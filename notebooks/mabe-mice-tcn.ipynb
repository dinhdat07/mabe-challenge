{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acfaf888",
   "metadata": {
    "papermill": {
     "duration": 0.007919,
     "end_time": "2025-12-05T10:46:17.072072",
     "exception": false,
     "start_time": "2025-12-05T10:46:17.064153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import and configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a91ff37b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:38:52.079625Z",
     "iopub.status.busy": "2025-12-09T12:38:52.078853Z",
     "iopub.status.idle": "2025-12-09T12:38:53.515306Z",
     "shell.execute_reply": "2025-12-09T12:38:53.514253Z",
     "shell.execute_reply.started": "2025-12-09T12:38:52.079597Z"
    },
    "papermill": {
     "duration": 3.266881,
     "end_time": "2025-12-05T10:46:20.345611",
     "exception": false,
     "start_time": "2025-12-05T10:46:17.078730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: koolbox in /usr/local/lib/python3.11/dist-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-deps koolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e67d5fb5",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2025-12-09T12:38:53.518070Z",
     "iopub.status.busy": "2025-12-09T12:38:53.517681Z",
     "iopub.status.idle": "2025-12-09T12:38:53.535440Z",
     "shell.execute_reply": "2025-12-09T12:38:53.534622Z",
     "shell.execute_reply.started": "2025-12-09T12:38:53.518041Z"
    },
    "papermill": {
     "duration": 2.442505,
     "end_time": "2025-12-05T10:46:22.794926",
     "exception": false,
     "start_time": "2025-12-05T10:46:20.352421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "def single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n",
    "    label_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "    prediction_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "    for row in lab_solution.to_dicts():\n",
    "        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n",
    "\n",
    "    for video in lab_solution['video_id'].unique():\n",
    "        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()  # ty: ignore\n",
    "        active_labels: set[str] = set(json.loads(active_labels))\n",
    "        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n",
    "            # Since the labels are sparse, we can't evaluate prediction keys not in the active labels.\n",
    "            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n",
    "                continue\n",
    "\n",
    "            new_frames = set(range(row['start_frame'], row['stop_frame']))\n",
    "            \n",
    "            # Ignore truly redundant predictions.\n",
    "            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n",
    "            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n",
    "            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n",
    "                # A single agent can have multiple targets per frame (ex: evading all other mice) but only one action per target per frame.\n",
    "                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n",
    "            \n",
    "            prediction_frames[row['prediction_key']].update(new_frames)\n",
    "            predicted_mouse_pairs[prediction_pair].update(new_frames)\n",
    "\n",
    "    tps = defaultdict(int)\n",
    "    fns = defaultdict(int)\n",
    "    fps = defaultdict(int)\n",
    "    for key, pred_frames in prediction_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        matched_label_frames = label_frames[key]\n",
    "        tps[action] += len(pred_frames.intersection(matched_label_frames))\n",
    "        fns[action] += len(matched_label_frames.difference(pred_frames))\n",
    "        fps[action] += len(pred_frames.difference(matched_label_frames))\n",
    "\n",
    "    distinct_actions = set()\n",
    "    for key, frames in label_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        distinct_actions.add(action)\n",
    "        if key not in prediction_frames:\n",
    "            fns[action] += len(frames)\n",
    "\n",
    "    action_f1s = []\n",
    "    for action in distinct_actions:\n",
    "        if tps[action] + fns[action] + fps[action] == 0:\n",
    "            action_f1s.append(0)\n",
    "        else:\n",
    "            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n",
    "    return sum(action_f1s) / len(action_f1s)\n",
    "\n",
    "def mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n",
    "\n",
    "    if len(solution) == 0 or len(submission) == 0:\n",
    "        raise ValueError('Missing solution or submission data')\n",
    "\n",
    "    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n",
    "\n",
    "    for col in expected_cols:\n",
    "        if col not in solution.columns:\n",
    "            raise ValueError(f'Solution is missing column {col}')\n",
    "        if col not in submission.columns:\n",
    "            raise ValueError(f'Submission is missing column {col}')\n",
    "\n",
    "    solution: pl.DataFrame = pl.DataFrame(solution)\n",
    "    submission: pl.DataFrame = pl.DataFrame(submission)\n",
    "    assert (solution['start_frame'] <= solution['stop_frame']).all()\n",
    "    assert (submission['start_frame'] <= submission['stop_frame']).all()\n",
    "    solution_videos = set(solution['video_id'].unique())\n",
    "    \n",
    "    # Need to align based on video IDs as we can't rely on the row IDs for handling public/private splits.\n",
    "    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n",
    "\n",
    "    solution = solution.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('label_key'),\n",
    "    )\n",
    "    submission = submission.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('prediction_key'),\n",
    "    )\n",
    "\n",
    "    lab_scores = []\n",
    "    for lab in solution['lab_id'].unique():\n",
    "        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n",
    "        lab_videos = set(lab_solution['video_id'].unique())\n",
    "        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n",
    "        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n",
    "\n",
    "    return sum(lab_scores) / len(lab_scores)\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n",
    "    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    return mouse_fbeta(solution, submission, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2e520b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:38:53.536248Z",
     "iopub.status.busy": "2025-12-09T12:38:53.536070Z",
     "iopub.status.idle": "2025-12-09T12:38:53.556485Z",
     "shell.execute_reply": "2025-12-09T12:38:53.555855Z",
     "shell.execute_reply.started": "2025-12-09T12:38:53.536233Z"
    },
    "papermill": {
     "duration": 11.391434,
     "end_time": "2025-12-05T10:46:34.193132",
     "exception": false,
     "start_time": "2025-12-05T10:46:22.801698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import clone\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "from koolbox import Trainer\n",
    "import numpy as np\n",
    "import itertools\n",
    "import optuna\n",
    "import warnings\n",
    "import joblib\n",
    "import glob\n",
    "import gc\n",
    "import logging\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "SEED = 1245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "840add11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:38:53.557622Z",
     "iopub.status.busy": "2025-12-09T12:38:53.557178Z",
     "iopub.status.idle": "2025-12-09T12:38:53.572362Z",
     "shell.execute_reply": "2025-12-09T12:38:53.571650Z",
     "shell.execute_reply.started": "2025-12-09T12:38:53.557604Z"
    },
    "papermill": {
     "duration": 0.016974,
     "end_time": "2025-12-05T10:46:34.217623",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.200649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class CFG:\n",
    "    train_path = \"/kaggle/input/MABe-mouse-behavior-detection/train.csv\"\n",
    "    test_path = \"/kaggle/input/MABe-mouse-behavior-detection/test.csv\"\n",
    "    train_annotation_path = \"/kaggle/input/MABe-mouse-behavior-detection/train_annotation\"\n",
    "    train_tracking_path = \"/kaggle/input/MABe-mouse-behavior-detection/train_tracking\"\n",
    "    test_tracking_path = \"/kaggle/input/MABe-mouse-behavior-detection/test_tracking\"\n",
    "\n",
    "    model_root = \"/kaggle/working\"\n",
    "    model_name = \"tcnn\"\n",
    "    model_dir = f\"{model_root}/{model_name}\"\n",
    "\n",
    "    patience = 5\n",
    "\n",
    "    # mode = \"submit\"\n",
    "    mode = \"validate\"\n",
    "    \n",
    "    n_splits = 3\n",
    "    cv = StratifiedGroupKFold(n_splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0ffc5",
   "metadata": {
    "papermill": {
     "duration": 0.006758,
     "end_time": "2025-12-05T10:46:34.231631",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.224873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dd25b83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:38:53.574234Z",
     "iopub.status.busy": "2025-12-09T12:38:53.574029Z",
     "iopub.status.idle": "2025-12-09T12:38:53.672082Z",
     "shell.execute_reply": "2025-12-09T12:38:53.671505Z",
     "shell.execute_reply.started": "2025-12-09T12:38:53.574219Z"
    },
    "papermill": {
     "duration": 0.145832,
     "end_time": "2025-12-05T10:46:34.384294",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.238462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(CFG.train_path)\n",
    "test = pd.read_csv(CFG.test_path)\n",
    "\n",
    "train[\"n_mice\"] = 4 - train[[\"mouse1_strain\", \"mouse2_strain\", \"mouse3_strain\", \"mouse4_strain\"]].isna().sum(axis=1)\n",
    "train_without_mbae = train.query(\"~lab_id.str.startswith('MABe22_')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5d711a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:38:53.672896Z",
     "iopub.status.busy": "2025-12-09T12:38:53.672710Z",
     "iopub.status.idle": "2025-12-09T12:38:53.679482Z",
     "shell.execute_reply": "2025-12-09T12:38:53.678783Z",
     "shell.execute_reply.started": "2025-12-09T12:38:53.672882Z"
    },
    "papermill": {
     "duration": 0.016672,
     "end_time": "2025-12-05T10:46:34.407904",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.391232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get unique raw entries\n",
    "body_parts_tracked_list = list(np.unique(train.body_parts_tracked))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e341ebe",
   "metadata": {
    "papermill": {
     "duration": 0.00742,
     "end_time": "2025-12-05T10:46:34.422435",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.415015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating label dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73f653b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:38:53.680533Z",
     "iopub.status.busy": "2025-12-09T12:38:53.680227Z",
     "iopub.status.idle": "2025-12-09T12:39:00.027403Z",
     "shell.execute_reply": "2025-12-09T12:39:00.026814Z",
     "shell.execute_reply.started": "2025-12-09T12:38:53.680509Z"
    },
    "papermill": {
     "duration": 0.016822,
     "end_time": "2025-12-05T10:46:34.445903",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.429081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74f5be078084392add7ab17e303bc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Files not found:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/input/MABe-mouse-behavior-detection/train_annotation/PleasantMeerkat/1375833299.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/139713291.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/167444193.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/329031399.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/361341393.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/484405601.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/610412175.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/687999061.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/801328824.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/834408298.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/1085312517.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/1366115611.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/1430299100.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/1543851393.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/1588709555.parquet', '/kaggle/input/MABe-mouse-behavior-detection/train_annotation/SparklingTapir/1772737271.parquet']\n"
     ]
    }
   ],
   "source": [
    "def create_solution_df(dataset):\n",
    "    solution = []\n",
    "    missing_file = []\n",
    "    for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        lab_id = row['lab_id']\n",
    "        \n",
    "        if lab_id.startswith('MABe22'): \n",
    "            continue\n",
    "            \n",
    "        video_id = row['video_id']\n",
    "        path = f\"{CFG.train_annotation_path}/{lab_id}/{video_id}.parquet\"\n",
    "        try:\n",
    "            anno = pd.read_parquet(path)\n",
    "        except FileNotFoundError:\n",
    "            missing_file.append(path)\n",
    "            continue\n",
    "\n",
    "        anno['lab_id'] = lab_id\n",
    "        anno['video_id'] = video_id\n",
    "        anno['behaviors_labeled'] = row['behaviors_labeled']\n",
    "        \n",
    "        anno['target_id'] = np.where(anno.target_id != anno.agent_id, anno['target_id'].apply(lambda s: f\"mouse{s}\"), 'self')\n",
    "        anno['agent_id'] = anno['agent_id'].apply(lambda s: f\"mouse{s}\")\n",
    "\n",
    "        solution.append(anno)\n",
    "    \n",
    "    solution = pd.concat(solution)\n",
    "    return solution, missing_file\n",
    "\n",
    "# use method above to create ground truth df\n",
    "if CFG.mode == 'validate':\n",
    "    solution, missing = create_solution_df(train_without_mbae)\n",
    "    logging.warning(\"Files not found:\")\n",
    "    print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0cc1598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.028428Z",
     "iopub.status.busy": "2025-12-09T12:39:00.028231Z",
     "iopub.status.idle": "2025-12-09T12:39:00.042025Z",
     "shell.execute_reply": "2025-12-09T12:39:00.041353Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.028412Z"
    },
    "papermill": {
     "duration": 0.025174,
     "end_time": "2025-12-05T10:46:34.478151",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.452977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DROP_BODY_PARTS = [\n",
    "    'headpiece_bottombackleft', 'headpiece_bottombackright',\n",
    "    'headpiece_bottomfrontleft', 'headpiece_bottomfrontright',\n",
    "    'headpiece_topbackleft', 'headpiece_topbackright',\n",
    "    'headpiece_topfrontleft', 'headpiece_topfrontright',\n",
    "    'spine_1', 'spine_2',\n",
    "    'tail_middle_1', 'tail_middle_2', 'tail_midpoint'\n",
    "]\n",
    "\n",
    "def generate_mouse_data(dataset, mode=None, is_train=True):\n",
    "    if is_train:\n",
    "        data_dir = CFG.train_tracking_path\n",
    "    else:\n",
    "        data_dir = CFG.test_tracking_path\n",
    "\n",
    "    for _, row in dataset.iterrows():\n",
    "        lab_id = row.lab_id\n",
    "\n",
    "        # skip if MABe lab or not string behaviors_labeled   \n",
    "        if lab_id.startswith(\"MABe22\") or not isinstance(row.behaviors_labeled, str):\n",
    "            continue\n",
    "\n",
    "        video_id = row.video_id\n",
    "        tracking_path =  f\"{data_dir}/{lab_id}/{video_id}.parquet\";\n",
    "\n",
    "        vid = pd.read_parquet(tracking_path)\n",
    "\n",
    "        # > 5 bodyparts -> drop\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            vid = vid.query(\"~bodypart.isin(@DROP_BODY_PARTS)\")\n",
    "\n",
    "        # pivot\n",
    "        pvid = vid.pivot(\n",
    "            index=\"video_frame\",\n",
    "            columns=[\"mouse_id\", \"bodypart\"],\n",
    "            values=[\"x\", \"y\"],\n",
    "        )\n",
    "\n",
    "        # delete vid for memory\n",
    "        del vid\n",
    "        gc.collect()\n",
    "\n",
    "        # (coor, mouse, bodypart) -> (mouse, bodypart, coor) -> sorted columns \n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n",
    "        \n",
    "        # pix to cm\n",
    "        pvid = pvid / row.pix_per_cm_approx\n",
    "        \n",
    "        # behaviors_labeled is JSON list\n",
    "        raw_behaviors = json.loads(row.behaviors_labeled)\n",
    "        \n",
    "        # remove ', duplicate by set then sort\n",
    "        cleaned = {b.replace(\"'\", \"\") for b in raw_behaviors} \n",
    "        cleaned = sorted(list(cleaned))\n",
    "\n",
    "        # split into 3 cols\n",
    "        behaviors_split = [b.split(\",\") for b in cleaned]\n",
    "        vid_beh = pd.DataFrame(behaviors_split, columns=[\"agent\", \"target\", \"action\"])\n",
    "\n",
    "        if is_train:\n",
    "            try: \n",
    "                anno_path = tracking_path.replace(\"train_tracking\", \"train_annotation\")\n",
    "                anno = pd.read_parquet(anno_path)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        \n",
    "        # ---- SINGLE MOUSE ----\n",
    "        if mode is None or mode == 'single' :\n",
    "            # only get target == self\n",
    "            vid_beh_single = vid_beh.query(\"target == 'self'\")\n",
    "\n",
    "            for agent_str in np.unique(vid_beh_single.agent):\n",
    "                try:\n",
    "                    # get the id (the last element of agent_str)\n",
    "                    mouse_id = int(agent_str[-1])\n",
    "                    \n",
    "                    # get all action of this agent \n",
    "                    agent_actions = np.unique(vid_beh_single.query(\"agent == @agent_str\").action)\n",
    "\n",
    "                    # get tracking of this agent\n",
    "                    single_mouse = pvid.loc[:, mouse_id] \n",
    "                    assert len(single_mouse) == len(pvid)\n",
    "                \n",
    "                    single_meta = pd.DataFrame({\n",
    "                        \"video_id\": video_id,\n",
    "                        \"agent_id\": agent_str,\n",
    "                        \"target_id\": \"self\",\n",
    "                        \"video_frame\": single_mouse.index, # index by frames\n",
    "                    })\n",
    "\n",
    "                    if is_train:\n",
    "                        single_label = pd.DataFrame(0.0, columns=agent_actions, index=single_mouse.index)\n",
    "                        anno_single = anno.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
    "\n",
    "                        for _, anno_row in anno_single.iterrows():\n",
    "                            start = anno_row['start_frame']\n",
    "                            end = anno_row['stop_frame']\n",
    "                            action = anno_row['action']\n",
    "                            single_label.loc[start:end, action] = 1.0\n",
    "\n",
    "                        yield \"single\", single_mouse, single_meta, single_label\n",
    "\n",
    "                    else:\n",
    "                        yield \"single\", single_mouse, single_meta, agent_actions\n",
    "                    \n",
    "                except KeyError:\n",
    "                    continue\n",
    "        \n",
    "        # ---- PAIR MOUSE ----\n",
    "        if mode is None or mode == 'pair':\n",
    "            # only get target != 'self'\n",
    "            vid_behaviors_pair = vid_beh.query(\"target != 'self'\")\n",
    "\n",
    "            if len(vid_behaviors_pair) == 0:\n",
    "                continue\n",
    "\n",
    "            # get list of mouse_ids\n",
    "            mouse_ids = np.unique(pvid.columns.get_level_values(\"mouse_id\"))\n",
    "\n",
    "            # permutation (agent, target) with agent != target\n",
    "            for agent_id, target_id in itertools.permutations(mouse_ids, 2):\n",
    "                agent_str = f\"mouse{agent_id}\"\n",
    "                target_str = f\"mouse{target_id}\"\n",
    "\n",
    "                # action of this (agent, target)\n",
    "                pair_actions = np.unique(\n",
    "                    vid_behaviors_pair.query(\"(agent == @agent_str) & (target == @target_str)\").action\n",
    "                )\n",
    "\n",
    "                # tracking of these 2 mice\n",
    "                mouse_pair = pd.concat(\n",
    "                    [pvid[agent_id], pvid[target_id]],\n",
    "                    axis=1,\n",
    "                    keys=[\"A\", \"B\"],  # A = agent, B = target\n",
    "                )\n",
    "                assert len(mouse_pair) == len(pvid)\n",
    "\n",
    "                # metadata \n",
    "                pair_meta = pd.DataFrame({\n",
    "                    \"video_id\": video_id,\n",
    "                    \"agent_id\": agent_str,\n",
    "                    \"target_id\": target_str,\n",
    "                    \"video_frame\": mouse_pair.index,\n",
    "                })\n",
    "\n",
    "                if is_train:\n",
    "                    # label: frame × action\n",
    "                    pair_label = pd.DataFrame(0.0, columns=pair_actions, index=mouse_pair.index)\n",
    "                    anno_pair = anno.query(\n",
    "                        \"(agent_id == @agent_id) & (target_id == @target_id)\"\n",
    "                    )\n",
    "\n",
    "                    for _, anno_row in anno_pair.iterrows():\n",
    "                        start = anno_row[\"start_frame\"]\n",
    "                        end = anno_row[\"stop_frame\"]\n",
    "                        action = anno_row[\"action\"]\n",
    "                        pair_label.loc[start:end, action] = 1.0\n",
    "\n",
    "                    yield \"pair\", mouse_pair, pair_meta, pair_label\n",
    "\n",
    "                else:\n",
    "                    # test/val: list action\n",
    "                    yield \"pair\", mouse_pair, pair_meta, pair_actions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5cc29",
   "metadata": {
    "papermill": {
     "duration": 0.006455,
     "end_time": "2025-12-05T10:46:34.491219",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.484764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3d04a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.043017Z",
     "iopub.status.busy": "2025-12-09T12:39:00.042710Z",
     "iopub.status.idle": "2025-12-09T12:39:00.059062Z",
     "shell.execute_reply": "2025-12-09T12:39:00.058334Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.042999Z"
    },
    "papermill": {
     "duration": 0.016493,
     "end_time": "2025-12-05T10:46:34.514517",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.498024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper\n",
    "\n",
    "def scaled_window(n_frames_30fps , fps , min_frac=0.2, min_abs=1):\n",
    "    ws = max(1, int(round(n_frames_30fps * float(fps) / 30.0)))\n",
    "    min_periods = max(min_abs, int(round(ws * min_frac)))\n",
    "    return ws, min_periods\n",
    "\n",
    "\n",
    "def _fps_from_meta(meta_df, fallback_lookup: dict, default_fps: float = 30.0):\n",
    "    if \"frames_per_second\" in meta_df.columns and pd.notnull(meta_df[\"frames_per_second\"]).any():\n",
    "        return float(meta_df[\"frames_per_second\"].iloc[0])\n",
    "    vid = meta_df[\"video_id\"].iloc[0]\n",
    "    return float(fallback_lookup.get(vid, default_fps))\n",
    "\n",
    "def _scale(n_frames_at_30fps, fps, ref=30.0):\n",
    "    return max(1, int(round(n_frames_at_30fps * float(fps) / ref)))\n",
    "\n",
    "def _scale_signed(n_frames_at_30fps, fps, ref=30.0):\n",
    "    if n_frames_at_30fps == 0:\n",
    "        return 0\n",
    "    s = 1 if n_frames_at_30fps > 0 else -1\n",
    "    mag = max(1, int(round(abs(n_frames_at_30fps) * float(fps) / ref)))\n",
    "    return s * mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdd09774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.060141Z",
     "iopub.status.busy": "2025-12-09T12:39:00.059811Z",
     "iopub.status.idle": "2025-12-09T12:39:00.078953Z",
     "shell.execute_reply": "2025-12-09T12:39:00.078234Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.060118Z"
    },
    "papermill": {
     "duration": 0.036602,
     "end_time": "2025-12-05T10:46:34.558318",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.521716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature for each mouse\n",
    "\n",
    "def add_curvature_features(X, center_x, center_y, fps):\n",
    "    # velocity & acceleration\n",
    "    vx = center_x.diff()\n",
    "    vy = center_y.diff()\n",
    "    ax = vx.diff()\n",
    "    ay = vy.diff()\n",
    "\n",
    "    # curve ~ |v × a| / |v|^3\n",
    "    cross = vx * ay - vy * ax\n",
    "    speed = np.sqrt(vx**2 + vy**2)\n",
    "    curvature = np.abs(cross) / (speed**3 + 1e-6)\n",
    "\n",
    "    # avg curve in scales\n",
    "    for base_w in [25, 50, 75]:\n",
    "        ws, mp = scaled_window(base_w, fps, min_frac=0.2)\n",
    "        X[f\"curv_mean_{base_w}\"] = curvature.rolling(ws, min_periods=mp).mean()\n",
    "    \n",
    "    angle = np.arctan2(vy, vx)\n",
    "    angle_change = np.abs(angle.diff())\n",
    "    ws, mp = scaled_window(30, fps, min_frac=0.2)\n",
    "    X[\"turn_rate_30\"] = angle_change.rolling(ws, min_periods=mp).sum()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_multiscale_features(X, center_x, center_y, fps):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "\n",
    "    scales = [20, 40, 60, 80]\n",
    "    for base_w in scales:\n",
    "        ws, mp = scaled_window(base_w, fps, min_frac=0.25)\n",
    "        if len(speed) >= ws:\n",
    "            X[f\"sp_m{base_w}\"] = speed.rolling(ws, min_periods=mp).mean()\n",
    "            X[f\"sp_s{base_w}\"] = speed.rolling(ws, min_periods=mp).std()\n",
    "\n",
    "    if all(f\"sp_m{s}\" in X.columns for s in (scales[0], scales[-1])):\n",
    "        X[\"sp_ratio\"] = X[f\"sp_m{scales[0]}\"] / (X[f\"sp_m{scales[-1]}\"] + 1e-6)\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_state_features(X, center_x, center_y, fps):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "\n",
    "    ws_ma, mp_ma = scaled_window(15, fps, min_frac=1/3)\n",
    "    speed_ma = speed.rolling(ws_ma, min_periods=mp_ma).mean()\n",
    "\n",
    "    try:\n",
    "        bins = [-np.inf, 0.5 * fps, 2.0 * fps, 5.0 * fps, np.inf]\n",
    "        speed_states = pd.cut(speed_ma, bins=bins, labels=[0, 1, 2, 3]).astype(float)\n",
    "\n",
    "        for base_w in [20, 40, 60, 80]:\n",
    "            ws, mp = scaled_window(base_w, fps, min_frac=0.2)\n",
    "            if len(speed_states) < ws:\n",
    "                continue\n",
    "\n",
    "            for state in [0, 1, 2, 3]:\n",
    "                X[f\"s{state}_{base_w}\"] = (\n",
    "                    (speed_states == state)\n",
    "                    .astype(float)\n",
    "                    .rolling(ws, min_periods=mp)\n",
    "                    .mean()\n",
    "                )\n",
    "\n",
    "            state_changes = (speed_states != speed_states.shift(1)).astype(float)\n",
    "            X[f\"trans_{base_w}\"] = state_changes.rolling(ws, min_periods=mp).sum()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_longrange_features(X, center_x, center_y, fps):\n",
    "    # longrange moving average\n",
    "    for base_w in [30, 60, 120]:\n",
    "        ws, mp = scaled_window(base_w, fps, min_frac=1/6, min_abs=5)\n",
    "        if len(center_x) >= ws:\n",
    "            X[f\"x_ml{base_w}\"] = center_x.rolling(ws, min_periods=mp).mean()\n",
    "            X[f\"y_ml{base_w}\"] = center_y.rolling(ws, min_periods=mp).mean()\n",
    "        \n",
    "    # EWMA \n",
    "    for span in [30, 60, 120]:\n",
    "        s, _ = scaled_window(span, fps, min_frac=0.0)  # min_periods sẽ set riêng\n",
    "        X[f\"x_e{span}\"] = center_x.ewm(span=s, min_periods=1).mean()\n",
    "        X[f\"y_e{span}\"] = center_y.ewm(span=s, min_periods=1).mean()\n",
    "\n",
    "    # percentile rank of speed\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "    for base_w in [30, 60, 120]:\n",
    "        ws, mp = scaled_window(base_w, fps, min_frac=1 / 6, min_abs=5)\n",
    "        if len(speed) >= ws:\n",
    "            X[f\"sp_pct{base_w}\"] = speed.rolling(ws, min_periods=mp).rank(pct=True)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd139f29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.080062Z",
     "iopub.status.busy": "2025-12-09T12:39:00.079756Z",
     "iopub.status.idle": "2025-12-09T12:39:00.096865Z",
     "shell.execute_reply": "2025-12-09T12:39:00.096298Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.080045Z"
    },
    "papermill": {
     "duration": 0.017402,
     "end_time": "2025-12-05T10:46:34.582239",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.564837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_single_extra_features(X, single_mouse, available_parts, fps):\n",
    "    # posture curvature\n",
    "    if all(p in available_parts for p in ['nose', 'body_center', 'tail_base']):\n",
    "        # body_center - tail_base vs nose - body_center\n",
    "        v1 = single_mouse['body_center'] - single_mouse['tail_base']\n",
    "        v2 = single_mouse['nose'] - single_mouse['body_center']\n",
    "\n",
    "        dot = v1['x'] * v2['x'] + v1['y'] * v2['y']\n",
    "        n1 = np.sqrt(v1['x']**2 + v1['y']**2)\n",
    "        n2 = np.sqrt(v2['x']**2 + v2['y']**2)\n",
    "\n",
    "        X['pose_curv'] = (dot / (n1 * n2 + 1e-6)).astype(np.float32)\n",
    "\n",
    "    # verticality/ rearing proxy\n",
    "    if all(p in available_parts for p in ['nose', 'lateral_left', 'lateral_right']):\n",
    "        nose_x = single_mouse['nose']['x']\n",
    "        nose_y = single_mouse['nose']['y']\n",
    "        lat_x = (single_mouse['lateral_left']['x'] + single_mouse['lateral_right']['x']) / 2.0\n",
    "        lat_y = (single_mouse['lateral_left']['y'] + single_mouse['lateral_right']['y']) / 2.0\n",
    "\n",
    "        nose_lat_dist = np.sqrt((nose_x - lat_x)**2 + (nose_y - lat_y)**2)\n",
    "        X[\"nose_lateral_dist\"] = nose_lat_dist.astype(np.float32)\n",
    "        X[\"nose_lateral_vel\"] = nose_lat_dist.diff().astype(np.float32)\n",
    "\n",
    "    # ear dynamics\n",
    "    if all(p in available_parts for p in ['ear_left', 'ear_right']):\n",
    "        ear_d = np.sqrt(\n",
    "            (single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "            (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2\n",
    "        )\n",
    "        X[\"ear_vel\"] = ear_d.diff().astype(np.float32)\n",
    "        X[\"ear_acc\"] = ear_d.diff().diff().astype(np.float32)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f8873cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.097783Z",
     "iopub.status.busy": "2025-12-09T12:39:00.097587Z",
     "iopub.status.idle": "2025-12-09T12:39:00.114377Z",
     "shell.execute_reply": "2025-12-09T12:39:00.113811Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.097764Z"
    },
    "papermill": {
     "duration": 0.027477,
     "end_time": "2025-12-05T10:46:34.616346",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.588869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_single(single_mouse, body_parts_tracked, fps):\n",
    "    available_parts = single_mouse.columns.get_level_values(0)\n",
    "\n",
    "    # pairwise distance between body part (p1, p2) ---\n",
    "    features = {}\n",
    "\n",
    "    for p1, p2 in itertools.combinations(body_parts_tracked, 2):\n",
    "        if p1 in available_parts and p2 in available_parts:\n",
    "            diff = single_mouse[p1] - single_mouse[p2]      # (x,y) or (x,y,...) by frame\n",
    "            dist2 = np.square(diff).sum(axis=1, skipna=False)\n",
    "            features[f\"{p1}+{p2}\"] = dist2\n",
    "\n",
    "    X = pd.DataFrame(features)\n",
    "\n",
    "    # ensure order\n",
    "    full_cols = [f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)]\n",
    "    X = X.reindex(columns=full_cols, copy=False)\n",
    "\n",
    "    # raw speed by ear and tail (lag ~10 frame) ---\n",
    "    if all(p in available_parts for p in ['ear_left', 'ear_right', 'tail_base']):\n",
    "        lag = _scale(10, fps)\n",
    "        past = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(lag)\n",
    "\n",
    "        sp_lf  = np.square(single_mouse['ear_left']  - past['ear_left']).sum(axis=1, skipna=False)\n",
    "        sp_rt  = np.square(single_mouse['ear_right'] - past['ear_right']).sum(axis=1, skipna=False)\n",
    "        sp_lf2 = np.square(single_mouse['ear_left']  - past['tail_base']).sum(axis=1, skipna=False)\n",
    "        sp_rt2 = np.square(single_mouse['ear_right'] - past['tail_base']).sum(axis=1, skipna=False)\n",
    "\n",
    "        X[['sp_lf', 'sp_rt', 'sp_lf2', 'sp_rt2']] = np.column_stack([sp_lf, sp_rt, sp_lf2, sp_rt2])\n",
    "\n",
    "    # elongation\n",
    "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "\n",
    "    # body angle\n",
    "    if all(p in available_parts for p in ['nose', 'body_center', 'tail_base']):\n",
    "        v1 = single_mouse['nose']      - single_mouse['body_center']\n",
    "        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n",
    "\n",
    "        dot = v1['x'] * v2['x'] + v1['y'] * v2['y']\n",
    "        norm1 = np.sqrt(v1['x']**2 + v1['y']**2)\n",
    "        norm2 = np.sqrt(v2['x']**2 + v2['y']**2)\n",
    "        body_ang = dot / (norm1 * norm2 + 1e-6)\n",
    "\n",
    "        X['body_ang'] = body_ang.astype(np.float32)\n",
    "        X['body_ang_vel'] = body_ang.diff().astype(np.float32)\n",
    "        X['body_ang_acc'] = body_ang.diff().diff().astype(np.float32)\n",
    "\n",
    "    # features by body_center\n",
    "    if 'body_center' in available_parts:\n",
    "        cx = single_mouse['body_center']['x']\n",
    "        cy = single_mouse['body_center']['y']\n",
    "\n",
    "        for base_w in [5, 15, 30, 60]:\n",
    "            ws = _scale(base_w, fps)\n",
    "            roll_kwargs = dict(window=ws, min_periods=1, center=True)\n",
    "\n",
    "            X[f'cx_m{base_w}'] = cx.rolling(**roll_kwargs).mean()\n",
    "            X[f'cy_m{base_w}'] = cy.rolling(**roll_kwargs).mean()\n",
    "            X[f'cx_s{base_w}'] = cx.rolling(**roll_kwargs).std()\n",
    "            X[f'cy_s{base_w}'] = cy.rolling(**roll_kwargs).std()\n",
    "\n",
    "            X[f'x_rng{base_w}'] = cx.rolling(**roll_kwargs).max() - cx.rolling(**roll_kwargs).min()\n",
    "            X[f'y_rng{base_w}'] = cy.rolling(**roll_kwargs).max() - cy.rolling(**roll_kwargs).min()\n",
    "\n",
    "            # displacement & activity (from diff)\n",
    "            dx = cx.diff()\n",
    "            dy = cy.diff()\n",
    "            disp = np.sqrt(dx.rolling(ws, min_periods=1).sum()**2 + dy.rolling(ws, min_periods=1).sum()**2)\n",
    "            act = np.sqrt(dx.rolling(ws, min_periods=1).var() + dy.rolling(ws, min_periods=1).var())\n",
    "            X[f'disp{base_w}'] = disp\n",
    "            X[f'act{base_w}']  = act\n",
    "\n",
    "        # advanced feature\n",
    "        X = add_curvature_features(X, cx, cy, fps)\n",
    "        X = add_multiscale_features(X, cx, cy, fps)\n",
    "        X = add_state_features(X, cx, cy, fps)\n",
    "        X = add_longrange_features(X, cx, cy, fps)\n",
    "\n",
    "    # nose–tail_based distance by time \n",
    "    if all(p in available_parts for p in ['nose', 'tail_base']):\n",
    "        nt = np.sqrt(\n",
    "            (single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "            (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2\n",
    "        )\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nt_lg{lag}'] = nt.shift(l)\n",
    "            X[f'nt_df{lag}'] = nt - nt.shift(l)\n",
    "\n",
    "    # ear distance & consistency\n",
    "    if all(p in available_parts for p in ['ear_left', 'ear_right']):\n",
    "        ear_d = np.sqrt(\n",
    "            (single_mouse['ear_left']['x']   - single_mouse['ear_right']['x'])**2 +\n",
    "            (single_mouse['ear_left']['y']   - single_mouse['ear_right']['y'])**2\n",
    "        )\n",
    "        # offset\n",
    "        for off in [-30, -20, -10, 10, 20, 30]:\n",
    "            o = _scale_signed(off, fps)\n",
    "            X[f'ear_o{off}'] = ear_d.shift(-o)\n",
    "\n",
    "        w = _scale(30, fps)\n",
    "        roll_c = dict(window=w, min_periods=1, center=True)\n",
    "        ear_mean = ear_d.rolling(**roll_c).mean()\n",
    "        ear_std  = ear_d.rolling(**roll_c).std()\n",
    "        X['ear_con'] = ear_std / (ear_mean + 1e-6)\n",
    "\n",
    "    X = add_single_extra_features(X, single_mouse, available_parts, fps)\n",
    "\n",
    "    return X.astype(np.float32, copy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcd80105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.115434Z",
     "iopub.status.busy": "2025-12-09T12:39:00.115190Z",
     "iopub.status.idle": "2025-12-09T12:39:00.131414Z",
     "shell.execute_reply": "2025-12-09T12:39:00.130724Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.115409Z"
    },
    "papermill": {
     "duration": 0.01857,
     "end_time": "2025-12-05T10:46:34.641788",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.623218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature for mice interaction\n",
    "def add_interaction_features(X, mouse_pair, avail_A, avail_B, fps):\n",
    "    if \"body_center\" not in avail_A or \"body_center\" not in avail_B:\n",
    "        return X\n",
    "    \n",
    "    # coor\n",
    "    Ax = mouse_pair[\"A\"][\"body_center\"][\"x\"]\n",
    "    Ay = mouse_pair[\"A\"][\"body_center\"][\"y\"]\n",
    "    Bx = mouse_pair[\"B\"][\"body_center\"][\"x\"]\n",
    "    By = mouse_pair[\"B\"][\"body_center\"][\"y\"]\n",
    "\n",
    "    # relative \n",
    "    rel_x = Ax - Bx\n",
    "    rel_y = Ay - By\n",
    "    rel_dist = np.sqrt(rel_x**2 + rel_y**2)\n",
    "\n",
    "    # velocity\n",
    "    A_vx = Ax.diff()\n",
    "    A_vy = Ay.diff()\n",
    "    B_vx = Bx.diff()\n",
    "    B_vy = By.diff()\n",
    "\n",
    "    # cosine angle between vector (A, B) and velocity vector\n",
    "    A_lead = (A_vx * rel_x + A_vy * rel_y) / (np.sqrt(A_vx**2 + A_vy**2) * rel_dist + 1e-6)\n",
    "    B_lead = (B_vx * (-rel_x) + B_vy * (-rel_y)) / (np.sqrt(B_vx**2 + B_vy**2) * rel_dist + 1e-6)\n",
    "\n",
    "    # avg of A_lead, B_lead on windows\n",
    "    for base_w in [30, 60]:\n",
    "        ws, mp = scaled_window(base_w, fps, min_frac=1 / 6)\n",
    "        X[f\"A_ld{base_w}\"] = A_lead.rolling(ws, min_periods=mp).mean()\n",
    "        X[f\"B_ld{base_w}\"] = B_lead.rolling(ws, min_periods=mp).mean()\n",
    "    \n",
    "    # approach\n",
    "    approach = -rel_dist.diff()\n",
    "    chase = approach * B_lead\n",
    "    ws, mp = scaled_window(30, fps, min_frac=1/6)\n",
    "    X[\"chase_30\"] = chase.rolling(ws, min_periods=mp).mean()\n",
    "\n",
    "    # correlation of 2 mice speed in long windows\n",
    "    A_sp = np.sqrt(A_vx**2 + A_vy**2)\n",
    "    B_sp = np.sqrt(B_vx**2 + B_vy**2)\n",
    "    for base_w in [60, 120]:\n",
    "        ws, mp = scaled_window(base_w, fps, min_frac=1 / 6)\n",
    "        X[f\"sp_cor{base_w}\"] = A_sp.rolling(ws, min_periods=mp).corr(B_sp)\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b113835c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.134576Z",
     "iopub.status.busy": "2025-12-09T12:39:00.133994Z",
     "iopub.status.idle": "2025-12-09T12:39:00.149425Z",
     "shell.execute_reply": "2025-12-09T12:39:00.148694Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.134554Z"
    },
    "papermill": {
     "duration": 0.020076,
     "end_time": "2025-12-05T10:46:34.668550",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.648474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_egocentric_interaction_features(X, mouse_pair, avail_A, avail_B, fps):\n",
    "    # cjeck condition\n",
    "    ok_A = all(p in avail_A for p in ['nose', 'tail_base', 'body_center'])\n",
    "    ok_B = all(p in avail_B for p in ['nose', 'tail_base', 'body_center'])\n",
    "    if not (ok_A and ok_B):\n",
    "        return X\n",
    "\n",
    "    # position\n",
    "    Ax = mouse_pair['A']['body_center']['x']\n",
    "    Ay = mouse_pair['A']['body_center']['y']\n",
    "    Bx = mouse_pair['B']['body_center']['x']\n",
    "    By = mouse_pair['B']['body_center']['y']\n",
    "\n",
    "    # head direction of A/B\n",
    "    headA_x = mouse_pair['A']['nose']['x'] - mouse_pair['A']['tail_base']['x']\n",
    "    headA_y = mouse_pair['A']['nose']['y'] - mouse_pair['A']['tail_base']['y']\n",
    "    headB_x = mouse_pair['B']['nose']['x'] - mouse_pair['B']['tail_base']['x']\n",
    "    headB_y = mouse_pair['B']['nose']['y'] - mouse_pair['B']['tail_base']['y']\n",
    "\n",
    "    # vector A → B\n",
    "    relAB_x = Bx - Ax\n",
    "    relAB_y = By - Ay\n",
    "\n",
    "    # cos / sin angle between A and vector A→B\n",
    "    dotA = headA_x * relAB_x + headA_y * relAB_y\n",
    "    norm_headA = np.sqrt(headA_x**2 + headA_y**2) + 1e-6\n",
    "    norm_relAB = np.sqrt(relAB_x**2 + relAB_y**2) + 1e-6\n",
    "\n",
    "    cos_bearing_A = dotA / (norm_headA * norm_relAB)\n",
    "    # sign of cross product → trái/phải\n",
    "    crossA = headA_x * relAB_y - headA_y * relAB_x\n",
    "    sin_bearing_A = crossA / (norm_headA * norm_relAB)\n",
    "\n",
    "    X['A_bearing_cos'] = cos_bearing_A.astype(np.float32)\n",
    "    X['A_bearing_sin'] = sin_bearing_A.astype(np.float32)\n",
    "\n",
    "    # for B\n",
    "    relBA_x = Ax - Bx\n",
    "    relBA_y = Ay - By\n",
    "    dotB = headB_x * relBA_x + headB_y * relBA_y\n",
    "    norm_headB = np.sqrt(headB_x**2 + headB_y**2) + 1e-6\n",
    "    norm_relBA = np.sqrt(relBA_x**2 + relBA_y**2) + 1e-6\n",
    "\n",
    "    cos_bearing_B = dotB / (norm_headB * norm_relBA)\n",
    "    crossB = headB_x * relBA_y - headB_y * relBA_x\n",
    "    sin_bearing_B = crossB / (norm_headB * norm_relBA)\n",
    "\n",
    "    X['B_bearing_cos'] = cos_bearing_B.astype(np.float32)\n",
    "    X['B_bearing_sin'] = sin_bearing_B.astype(np.float32)\n",
    "\n",
    "    # rolling stats \n",
    "    for base_w in [15, 30]:\n",
    "        ws = _scale(base_w, fps)\n",
    "        roll = dict(window=ws, min_periods=1, center=True)\n",
    "        X[f'A_bearing_cos_m{base_w}'] = X['A_bearing_cos'].rolling(**roll).mean()\n",
    "        X[f'A_bearing_sin_m{base_w}'] = X['A_bearing_sin'].rolling(**roll).mean()\n",
    "        X[f'B_bearing_cos_m{base_w}'] = X['B_bearing_cos'].rolling(**roll).mean()\n",
    "        X[f'B_bearing_sin_m{base_w}'] = X['B_bearing_sin'].rolling(**roll).mean()\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa1a5a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.150856Z",
     "iopub.status.busy": "2025-12-09T12:39:00.150253Z",
     "iopub.status.idle": "2025-12-09T12:39:00.167700Z",
     "shell.execute_reply": "2025-12-09T12:39:00.166961Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.150832Z"
    },
    "papermill": {
     "duration": 0.017129,
     "end_time": "2025-12-05T10:46:34.692151",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.675022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_asymmetry_features(X, mouse_pair, avail_A, avail_B, fps):\n",
    "    # need body_center to define speeds\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "\n",
    "    Ax = mouse_pair['A']['body_center']['x']\n",
    "    Ay = mouse_pair['A']['body_center']['y']\n",
    "    Bx = mouse_pair['B']['body_center']['x']\n",
    "    By = mouse_pair['B']['body_center']['y']\n",
    "\n",
    "    # velocities (frame-wise differences)\n",
    "    A_vx = Ax.diff()\n",
    "    A_vy = Ay.diff()\n",
    "    B_vx = Bx.diff()\n",
    "    B_vy = By.diff()\n",
    "\n",
    "    # instantaneous speeds\n",
    "    A_sp = np.sqrt(A_vx**2 + A_vy**2)\n",
    "    B_sp = np.sqrt(B_vx**2 + B_vy**2)\n",
    "\n",
    "    # asymmetry: difference and ratio\n",
    "    sp_diff = A_sp - B_sp\n",
    "    sp_ratio = A_sp / (B_sp + 1e-6)\n",
    "\n",
    "    X['sp_diff_inst'] = sp_diff.astype(np.float32)\n",
    "    X['sp_ratio_inst'] = sp_ratio.astype(np.float32)\n",
    "\n",
    "    # rolling stats over short/medium windows\n",
    "    for base_w in [30, 60]:\n",
    "        ws = _scale(base_w, fps)\n",
    "        roll = dict(window=ws, min_periods=1, center=True)\n",
    "\n",
    "        X[f'sp_diff_m{base_w}'] = (\n",
    "            sp_diff.rolling(**roll).mean().astype(np.float32)\n",
    "        )\n",
    "        X[f'sp_ratio_m{base_w}'] = (\n",
    "            sp_ratio.rolling(**roll).mean().astype(np.float32)\n",
    "        )\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "115a9b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.168887Z",
     "iopub.status.busy": "2025-12-09T12:39:00.168582Z",
     "iopub.status.idle": "2025-12-09T12:39:00.191423Z",
     "shell.execute_reply": "2025-12-09T12:39:00.190708Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.168869Z"
    },
    "papermill": {
     "duration": 0.033516,
     "end_time": "2025-12-05T10:46:34.732335",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.698819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_pair(mouse_pair, body_parts_tracked, fps):\n",
    "    avail_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    avail_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "\n",
    "    # pairwise distance between A[p1] and B[p2]\n",
    "    features = {}\n",
    "    for p1, p2 in itertools.product(body_parts_tracked, repeat=2):\n",
    "        if p1 in avail_A and p2 in avail_B:\n",
    "            diff = mouse_pair['A'][p1] - mouse_pair['B'][p2]\n",
    "            dist2 = np.square(diff).sum(axis=1, skipna=False)\n",
    "            features[f\"12+{p1}+{p2}\"] = dist2\n",
    "\n",
    "    X = pd.DataFrame(features)\n",
    "    full_cols = [f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)]\n",
    "    X = X.reindex(columns=full_cols, copy=False)\n",
    "\n",
    "    # ear-left speed A/B (lag ~10 frame)\n",
    "    if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n",
    "        lag = _scale(10, fps)\n",
    "        shA = mouse_pair['A']['ear_left'].shift(lag)\n",
    "        shB = mouse_pair['B']['ear_left'].shift(lag)\n",
    "\n",
    "        sp_A  = np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False)\n",
    "        sp_AB = np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False)\n",
    "        sp_B  = np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False)\n",
    "\n",
    "        X[['sp_A', 'sp_AB', 'sp_B']] = np.column_stack([sp_A, sp_AB, sp_B])\n",
    "\n",
    "    # elong = dist(nose, tail_base) / dist(ear_left, ear_right)\n",
    "    have_A_elong = all(p in avail_A for p in ['nose', 'tail_base', 'ear_left', 'ear_right'])\n",
    "    have_B_elong = all(p in avail_B for p in ['nose', 'tail_base', 'ear_left', 'ear_right'])\n",
    "\n",
    "    if have_A_elong:\n",
    "        nose_A = mouse_pair['A']['nose']\n",
    "        tail_A = mouse_pair['A']['tail_base']\n",
    "        el_A_l = mouse_pair['A']['ear_left']\n",
    "        el_A_r = mouse_pair['A']['ear_right']\n",
    "\n",
    "        nose_tail_A = np.square(nose_A - tail_A).sum(axis=1, skipna=False)\n",
    "        ear_dist_A  = np.square(el_A_l - el_A_r).sum(axis=1, skipna=False)\n",
    "        X['elong_A'] = nose_tail_A / (ear_dist_A + 1e-6)\n",
    "\n",
    "    if have_B_elong:\n",
    "        nose_B = mouse_pair['B']['nose']\n",
    "        tail_B = mouse_pair['B']['tail_base']\n",
    "        el_B_l = mouse_pair['B']['ear_left']\n",
    "        el_B_r = mouse_pair['B']['ear_right']\n",
    "\n",
    "        nose_tail_B = np.square(nose_B - tail_B).sum(axis=1, skipna=False)\n",
    "        ear_dist_B  = np.square(el_B_l - el_B_r).sum(axis=1, skipna=False)\n",
    "        X['elong_B'] = nose_tail_B / (ear_dist_B + 1e-6)\n",
    "\n",
    "    # diff and ratio\n",
    "    if 'elong_A' in X.columns and 'elong_B' in X.columns:\n",
    "        X['elong_diff']  = X['elong_A'] - X['elong_B']\n",
    "        X['elong_ratio'] = X['elong_A'] / (X['elong_B'] + 1e-6)\n",
    "\n",
    "    # relative body angle between A and B\n",
    "    if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n",
    "        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n",
    "        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n",
    "\n",
    "        dot = dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']\n",
    "        nA = np.sqrt(dir_A['x']**2 + dir_A['y']**2)\n",
    "        nB = np.sqrt(dir_B['x']**2 + dir_B['y']**2)\n",
    "        X['rel_ori'] = dot / (nA * nB + 1e-6)\n",
    "\n",
    "    # nose-nose approach\n",
    "    if 'nose' in avail_A and 'nose' in avail_B:\n",
    "        nn_cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n",
    "        lag = _scale(10, fps)\n",
    "        shA_n = mouse_pair['A']['nose'].shift(lag)\n",
    "        shB_n = mouse_pair['B']['nose'].shift(lag)\n",
    "        nn_past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n",
    "        X['appr'] = nn_cur - nn_past\n",
    "\n",
    "    # distance categories by body_center\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        Ax = mouse_pair['A']['body_center']['x']\n",
    "        Ay = mouse_pair['A']['body_center']['y']\n",
    "        Bx = mouse_pair['B']['body_center']['x']\n",
    "        By = mouse_pair['B']['body_center']['y']\n",
    "\n",
    "        cd = np.sqrt((Ax - Bx)**2 + (Ay - By)**2)\n",
    "\n",
    "        X['v_cls'] = (cd < 5.0).astype(float)\n",
    "        X['cls']   = ((cd >= 5.0)  & (cd < 15.0)).astype(float)\n",
    "        X['med']   = ((cd >= 15.0) & (cd < 30.0)).astype(float)\n",
    "        X['far']   = (cd >= 30.0).astype(float)\n",
    "\n",
    "        # stats on squared distance\n",
    "        cd2 = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n",
    "        \n",
    "        for base_w in [5, 15, 30, 60]:\n",
    "            ws = _scale(base_w, fps)\n",
    "            roll_c = dict(window=ws, min_periods=1, center=True)\n",
    "    \n",
    "            X[f'd_m{base_w}']  = cd2.rolling(**roll_c).mean()\n",
    "            X[f'd_s{base_w}']  = cd2.rolling(**roll_c).std()\n",
    "            X[f'd_mn{base_w}'] = cd2.rolling(**roll_c).min()\n",
    "            X[f'd_mx{base_w}'] = cd2.rolling(**roll_c).max()\n",
    "    \n",
    "            d_var = cd2.rolling(**roll_c).var()\n",
    "            X[f'int{base_w}'] = 1.0 / (1.0 + d_var)\n",
    "    \n",
    "            # dot product vận tốc body_center\n",
    "            Axd = Ax.diff()\n",
    "            Ayd = Ay.diff()\n",
    "            Bxd = Bx.diff()\n",
    "            Byd = By.diff()\n",
    "            coord = Axd * Bxd + Ayd * Byd\n",
    "            X[f'co_m{base_w}'] = coord.rolling(**roll_c).mean()\n",
    "            X[f'co_s{base_w}'] = coord.rolling(**roll_c).std()\n",
    "\n",
    "            # cosine similarity A,B speed (offset) ---\n",
    "            Avx = Ax.diff()\n",
    "            Avy = Ay.diff()\n",
    "            Bvx = Bx.diff()\n",
    "            Bvy = By.diff()\n",
    "            vel_cos = (Avx * Bvx + Avy * Bvy) / (\n",
    "                np.sqrt(Avx**2 + Avy**2) * np.sqrt(Bvx**2 + Bvy**2) + 1e-6\n",
    "            )\n",
    "        \n",
    "            for off in [-30, -20, -10, 0, 10, 20, 30]:\n",
    "                o = _scale_signed(off, fps)\n",
    "                X[f'va_{off}'] = vel_cos.shift(-o)\n",
    "        \n",
    "            w = _scale(30, fps)\n",
    "            roll_c30 = dict(window=w, min_periods=1, center=True)\n",
    "            cd2_mean = cd2.rolling(**roll_c30).mean()\n",
    "            cd2_std  = cd2.rolling(**roll_c30).std()\n",
    "            X['int_con'] = cd2_std / (cd2_mean + 1e-6)\n",
    "\n",
    "            # advanced features\n",
    "            X = add_asymmetry_features(X, mouse_pair, avail_A, avail_B, fps)\n",
    "            X = add_egocentric_interaction_features(X, mouse_pair, avail_A, avail_B, fps)\n",
    "            X = add_interaction_features(X, mouse_pair, avail_A, avail_B, fps)\n",
    "\n",
    "    # nose-nose distance + close percentage\n",
    "    if 'nose' in avail_A and 'nose' in avail_B:\n",
    "        nn = np.sqrt(\n",
    "            (mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "            (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2\n",
    "        )\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nn_lg{lag}'] = nn.shift(l)\n",
    "            X[f'nn_ch{lag}'] = nn - nn.shift(l)\n",
    "            is_close = (nn < 10.0).astype(float)\n",
    "            X[f'cl_ps{lag}'] = is_close.rolling(l, min_periods=1).mean()\n",
    "    \n",
    "\n",
    "    return X.astype(np.float32, copy=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0d030",
   "metadata": {
    "papermill": {
     "duration": 0.006522,
     "end_time": "2025-12-05T10:46:34.745355",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.738833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a28fd0bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.192467Z",
     "iopub.status.busy": "2025-12-09T12:39:00.192252Z",
     "iopub.status.idle": "2025-12-09T12:39:00.210382Z",
     "shell.execute_reply": "2025-12-09T12:39:00.209745Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.192453Z"
    },
    "papermill": {
     "duration": 0.021847,
     "end_time": "2025-12-05T10:46:34.773547",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.751700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_and_fill_submission(submission, meta_df, is_train=True):\n",
    "    if is_train:\n",
    "        tracking_dir = CFG.train_tracking_path\n",
    "    else: \n",
    "        tracking_dir = CFG.test_tracking_path\n",
    "    \n",
    "    # remove where start >= stop\n",
    "    prev_len = len(submission)\n",
    "    submission = submission[submission['start_frame'] < submission['stop_frame']].copy()\n",
    "    if len(submission) != prev_len:\n",
    "        print(\"Dropped rows with start_frame > stop_frame\")\n",
    "    \n",
    "    # remove overlap\n",
    "    prev_len = len(submission)\n",
    "    cleaned_groups = []\n",
    "\n",
    "    for (_, grp) in submission.groupby(['video_id', 'agent_id', 'target_id']):\n",
    "        grp = grp.sort_values('start_frame')\n",
    "        keep_mask = np.ones(len(grp), dtype=bool)\n",
    "\n",
    "        last_stop = -1\n",
    "        for i, (_, row) in enumerate(grp.iterrows()):\n",
    "            if row['start_frame'] < last_stop:\n",
    "                keep_mask[i] = False\n",
    "            else:\n",
    "                last_stop = row['stop_frame']\n",
    "        \n",
    "        cleaned_groups.append(grp[keep_mask])\n",
    "\n",
    "    submission = pd.concat(cleaned_groups, ignore_index=True)\n",
    "    if len(submission) != prev_len:\n",
    "        print(\"Dropped rows with overlapped intervals\")   \n",
    "\n",
    "    # dummy prediction for video have no prediction\n",
    "    dummy_rows = []\n",
    "\n",
    "    for _, row in meta_df.iterrows():\n",
    "        lab_id = row[\"lab_id\"]\n",
    "\n",
    "        # remove MABe22 vids\n",
    "        if isinstance(lab_id, str) and lab_id.startswith(\"MABe22\"):\n",
    "            continue\n",
    "        \n",
    "        # remove behaviors_labeled if not string\n",
    "        if not isinstance(row.get(\"behaviors_labeled\", None), str):\n",
    "            continue\n",
    "\n",
    "        video_id = row[\"video_id\"]\n",
    "\n",
    "        # if have prediction -> skip\n",
    "        if (submission[\"video_id\"] == video_id).any():\n",
    "            continue\n",
    "\n",
    "        print(f\"Video {video_id} has no predictions. Filling dummy segments...\")\n",
    "\n",
    "        # read tracking\n",
    "        path = f\"{tracking_dir}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "\n",
    "        # get list (agent, target, action) from meta\n",
    "        raw_behaviors = json.loads(row[\"behaviors_labeled\"])\n",
    "        cleaned = {b.replace(\"'\", \"\") for b in raw_behaviors}\n",
    "        triplets = [b.split(\",\") for b in sorted(cleaned)]\n",
    "        beh_df = pd.DataFrame(triplets, columns=[\"agent\", \"target\", \"action\"])\n",
    "\n",
    "        # get total frames of this video\n",
    "        start_frame = vid[\"video_frame\"].min()\n",
    "        stop_frame = vid[\"video_frame\"].max() + 1\n",
    "        total_frames = stop_frame - start_frame\n",
    "\n",
    "        # divide uniformly \n",
    "        for (agent, target), actions in beh_df.groupby([\"agent\", \"target\"]):\n",
    "            n_actions = len(actions)\n",
    "            if n_actions == 0:\n",
    "                continue\n",
    "\n",
    "            batch_len = int(np.ceil(total_frames / n_actions))\n",
    "\n",
    "            for i, (_, act_row) in enumerate(actions.iterrows()):\n",
    "                batch_start = start_frame + i * batch_len\n",
    "                batch_stop = min(batch_start + batch_len, stop_frame)\n",
    "\n",
    "                dummy_rows.append((\n",
    "                    video_id,\n",
    "                    act_row[\"agent\"],\n",
    "                    act_row[\"target\"],\n",
    "                    act_row[\"action\"],\n",
    "                    batch_start,\n",
    "                    batch_stop,\n",
    "                ))\n",
    "\n",
    "    if dummy_rows:\n",
    "        dummy_df = pd.DataFrame(\n",
    "            dummy_rows,\n",
    "            columns=[\"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"],\n",
    "        )\n",
    "        submission = pd.concat([submission, dummy_df], ignore_index=True)\n",
    "        print(f\"Filled {len(dummy_rows)} dummy segments for empty videos\")\n",
    "\n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15a1651d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.211174Z",
     "iopub.status.busy": "2025-12-09T12:39:00.211009Z",
     "iopub.status.idle": "2025-12-09T12:39:00.228244Z",
     "shell.execute_reply": "2025-12-09T12:39:00.227669Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.211161Z"
    },
    "papermill": {
     "duration": 0.017221,
     "end_time": "2025-12-05T10:46:34.823669",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.806448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tune_thresholds_per_class(y_true, y_pred_prob, class_names):\n",
    "    best_thrs = {}\n",
    "    best_f1s = {}\n",
    "    \n",
    "    # tạo mảng ngưỡng (1 dòng, 99 cột)\n",
    "    thresholds = np.arange(0.01, 1.00, 0.01)\n",
    "    \n",
    "    # loop qua từng class (không tránh được, nhưng bên trong sẽ rất nhanh)\n",
    "    for i, name in enumerate(class_names):\n",
    "        y_t = y_true[:, i]      # Shape: (N,)\n",
    "        y_p = y_pred_prob[:, i] # Shape: (N,)\n",
    "        \n",
    "        # Nếu không có mẫu dương nào, skip ngay\n",
    "        if y_t.sum() == 0: \n",
    "            best_thrs[name] = 0.5\n",
    "            best_f1s[name] = 0.0\n",
    "            continue\n",
    "        \n",
    "        # --- BƯỚC CẢI TIẾN: VECTOR HÓA ---\n",
    "        \n",
    "        # 1. So sánh y_p với TẤT CẢ ngưỡng cùng lúc\n",
    "        # y_p[:, None] shape là (N, 1)\n",
    "        # thresholds[None, :] shape là (1, 99)\n",
    "        # Kết quả pred_matrix shape là (N, 99) - Ma trận True/False\n",
    "        pred_matrix = (y_p[:, None] >= thresholds[None, :])\n",
    "        \n",
    "        # 2. Tính True Positive (TP), False Positive (FP), False Negative (FN)\n",
    "        # Nhân với y_t[:, None] (Shape N, 1) để broadcast\n",
    "        \n",
    "        # TP: Dự đoán True VÀ Thực tế True\n",
    "        tp = (pred_matrix & (y_t[:, None] == 1)).sum(axis=0)\n",
    "        \n",
    "        # FP: Dự đoán True NHƯNG Thực tế False\n",
    "        fp = (pred_matrix & (y_t[:, None] == 0)).sum(axis=0)\n",
    "        \n",
    "        # FN: Dự đoán False NHƯNG Thực tế True\n",
    "        # (~pred_matrix) đảo ngược True/False\n",
    "        fn = ((~pred_matrix) & (y_t[:, None] == 1)).sum(axis=0)\n",
    "        \n",
    "        # 3. Tính F1 Score cho cả 99 ngưỡng cùng lúc theo công thức\n",
    "        # F1 = 2TP / (2TP + FP + FN)\n",
    "        epsilon = 1e-7 # Tránh chia cho 0\n",
    "        f1_scores = 2 * tp / (2 * tp + fp + fn + epsilon)\n",
    "        \n",
    "        # 4. Tìm vị trí có F1 cao nhất\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        \n",
    "        best_f1 = f1_scores[best_idx]\n",
    "        best_thr = thresholds[best_idx]\n",
    "        \n",
    "        best_thrs[name] = float(best_thr)\n",
    "        best_f1s[name] = float(best_f1)\n",
    "        \n",
    "    return best_thrs, best_f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a99beb44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.229419Z",
     "iopub.status.busy": "2025-12-09T12:39:00.229152Z",
     "iopub.status.idle": "2025-12-09T12:39:00.270586Z",
     "shell.execute_reply": "2025-12-09T12:39:00.269851Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.229397Z"
    },
    "papermill": {
     "duration": 0.052423,
     "end_time": "2025-12-05T10:46:34.910826",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.858403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Tắt warning\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "MODEL_DIR = getattr(CFG, \"model_dir\", CFG.model_name)\n",
    "if not os.path.exists(MODEL_DIR): os.makedirs(MODEL_DIR)\n",
    "\n",
    "\n",
    "# --- CLASS: EARLY STOPPING ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_f1, model, path):\n",
    "        score = val_f1\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model, path)\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_f1, model, path):\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "# --- LOSS: FOCAL LOSS ---\n",
    "class FocalBCEWithLogitsLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits, targets, pos_weight=self.pos_weight, reduction='none'\n",
    "        )\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt = torch.where(targets == 1, probs, 1 - probs)\n",
    "        loss = (1 - pt) ** self.gamma * bce_loss\n",
    "        \n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        elif self.reduction == 'sum': return loss.sum()\n",
    "        else: return loss\n",
    "\n",
    "# ==========================================\n",
    "# 1. PARAMETERS\n",
    "# ==========================================\n",
    "WINDOW_SIZE = 30  \n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 2       \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATASET\n",
    "# ==========================================\n",
    "class MABeLazyDataset(Dataset):\n",
    "    def __init__(self, feat_list_np, scaler, label_list=None, window_size=30):\n",
    "        self.window_size = window_size\n",
    "        self.feat_list = feat_list_np   \n",
    "        self.label_list = label_list\n",
    "        self.scaler = scaler\n",
    "        \n",
    "        # Tạo index map\n",
    "        self.index_map = []\n",
    "        for v_idx, arr in enumerate(self.feat_list):\n",
    "            length = len(arr)\n",
    "            if length >= window_size:\n",
    "                self.index_map.extend([(v_idx, t) for t in range(length - window_size)])\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.index_map)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        v_idx, t = self.index_map[idx]\n",
    "        \n",
    "        # Slicing trên Numpy nhanh hơn Pandas .iloc rất nhiều\n",
    "        window = self.feat_list[v_idx][t : t + self.window_size]\n",
    "        \n",
    "        # Scale \"On-the-fly\"\n",
    "        if self.scaler is not None:\n",
    "            window = self.scaler.transform(window)\n",
    "        \n",
    "        # Transpose: (Seq, Feat) -> (Feat, Seq)\n",
    "        X_out = torch.tensor(window, dtype=torch.float32).transpose(0, 1)\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            center_frame_idx = t + self.window_size // 2\n",
    "            y_out = torch.tensor(self.label_list[v_idx][center_frame_idx], dtype=torch.float32)\n",
    "            return X_out, y_out\n",
    "        else: \n",
    "            return X_out\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL: RESNET-1D\n",
    "# ==========================================\n",
    "class ResidualBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation // 2\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return self.relu(x)\n",
    "\n",
    "class MouseTCN(nn.Module):\n",
    "    def __init__(self, n_feat=151, n_class=8, base_filters=64):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv1d(n_feat, base_filters, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(base_filters), nn.ReLU()\n",
    "        )\n",
    "        self.layer1 = ResidualBlock1D(base_filters, base_filters, dilation=1)\n",
    "        self.layer2 = ResidualBlock1D(base_filters, base_filters*2, dilation=2)\n",
    "        self.layer3 = ResidualBlock1D(base_filters*2, base_filters*4, dilation=4)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1) \n",
    "        self.fc = nn.Linear(base_filters*4, n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp):\n",
    "        super().__init__()\n",
    "        self.chomp = chomp\n",
    "    def forward(self, x):\n",
    "        return x[..., :-self.chomp] if self.chomp > 0 else x\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, d=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        pad = (k - 1) * d\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, k, padding=pad, dilation=d),\n",
    "            Chomp1d(pad),\n",
    "            nn.BatchNorm1d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(out_ch, out_ch, k, padding=pad, dilation=d),\n",
    "            Chomp1d(pad),\n",
    "            nn.BatchNorm1d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.down = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU()(self.net(x) + self.down(x))\n",
    "\n",
    "class MouseTCN(nn.Module):\n",
    "    def __init__(self, n_feat=151, n_class=8, channels=(64, 64, 128, 128), k=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        blocks = []\n",
    "        in_c = n_feat\n",
    "        for i, out_c in enumerate(channels):\n",
    "            blocks.append(TemporalBlock(in_c, out_c, k=k, d=2**i, dropout=dropout))\n",
    "            in_c = out_c\n",
    "        self.tcn = nn.Sequential(*blocks)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(in_c, n_class)\n",
    "    def forward(self, x):\n",
    "        x = self.tcn(x)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "# ==========================================\n",
    "# 4. TRAINING FUNCTION (GPU OPTIMIZED)\n",
    "# ==========================================\n",
    "def train_evaluate_cnn(feat_list, label_list, meta_list, section, mode, n_splits=3):\n",
    "    if not os.path.exists(MODEL_DIR): os.makedirs(MODEL_DIR)\n",
    "\n",
    "    # CHUYỂN ĐỔI DATA SANG NUMPY ---\n",
    "    print(\">>> Optimizing: Converting DataFrames to Numpy (CPU heavy once, then fast)...\")\n",
    "    \n",
    "    # Union features\n",
    "    ref_cols = sorted({c for df in feat_list for c in df.columns})\n",
    "\n",
    "    # Convert toàn bộ feat_list\n",
    "    feat_list_np = []\n",
    "    for df in tqdm(feat_list, desc=\"To Numpy\"):\n",
    "        arr = df.reindex(columns=ref_cols, fill_value=0).values.astype(np.float32)\n",
    "        arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        feat_list_np.append(arr)\n",
    "\n",
    "    del feat_list\n",
    "    gc.collect()\n",
    "\n",
    "    # XỬ LÝ LABELS\n",
    "    if label_list:\n",
    "        all_actions = set()\n",
    "        for df in label_list: all_actions.update(df.columns)\n",
    "        ref_label_cols = sorted(list(all_actions))\n",
    "        # Label cũng chuyển sang Numpy list\n",
    "        label_list_np = [df.reindex(columns=ref_label_cols, fill_value=0).values.astype(np.float32) for df in label_list]\n",
    "    else:\n",
    "        label_list_np = None\n",
    "        # Dummy ref_cols nếu ko có label (chỉ chạy inference)\n",
    "        ref_label_cols = [\"dummy\"] \n",
    "\n",
    "    # CHIA FOLD\n",
    "    video_indices = np.arange(len(feat_list_np))\n",
    "    video_labels = [] \n",
    "    if label_list_np:\n",
    "        for arr in label_list_np:\n",
    "            counts = arr.sum(axis=0)\n",
    "            if counts.sum() == 0: video_labels.append(-1)\n",
    "            else: video_labels.append(np.argmax(counts))\n",
    "    else:\n",
    "        video_labels = [0] * len(feat_list_np)\n",
    "\n",
    "    video_labels = np.array(video_labels)\n",
    "    video_groups = video_indices \n",
    "\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    fold_scores = []\n",
    "    \n",
    "    # Biến để return\n",
    "    model = None\n",
    "    scaler = None\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(sgkf.split(video_indices, video_labels, video_groups)):\n",
    "        print(f\"\\n>>> TRAINING FOLD {fold+1}/{n_splits} <<<\")\n",
    "        \n",
    "        # Lấy dữ liệu từ Numpy list (Siêu nhanh)\n",
    "        train_feats = [feat_list_np[i] for i in train_idx]\n",
    "        val_feats = [feat_list_np[i] for i in val_idx]\n",
    "        \n",
    "        train_lbls = [label_list_np[i] for i in train_idx] if label_list_np else None\n",
    "        val_lbls = [label_list_np[i] for i in val_idx] if label_list_np else None\n",
    "        \n",
    "        # --- SCALING ---\n",
    "        print(\"Fitting Scaler...\")\n",
    "        scaler = StandardScaler()\n",
    "        # Partial fit trên Numpy array\n",
    "        for arr in tqdm(train_feats, desc=\"Fitting Scaler\", leave=False):\n",
    "            scaler.partial_fit(arr) \n",
    "        \n",
    "        # --- DATASET & DATALOADER ---\n",
    "        ds_train = MABeLazyDataset(train_feats, scaler, train_lbls, window_size=WINDOW_SIZE)\n",
    "        ds_val = MABeLazyDataset(val_feats, scaler, val_lbls, window_size=WINDOW_SIZE)\n",
    "        \n",
    "        # Tăng Batch Size & Num Workers\n",
    "        # Batch Size: 1024 (Tận dụng GPU)\n",
    "        # Num Workers: 4 (Tải dữ liệu song song)\n",
    "        train_bs = getattr(CFG, 'train_batch_size', 256)\n",
    "        val_bs = getattr(CFG, 'val_batch_size', max(train_bs*2, train_bs))\n",
    "        loader_train = DataLoader(ds_train, batch_size=train_bs, shuffle=True, num_workers=2, pin_memory=True) \n",
    "        loader_val = DataLoader(ds_val, batch_size=val_bs, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        \n",
    "        # --- CALCULATE POS_WEIGHT ---\n",
    "        pos_counts = np.zeros(len(ref_label_cols))\n",
    "        total_samples = 0\n",
    "        if train_lbls:\n",
    "            for arr in train_lbls:\n",
    "                if len(arr) >= WINDOW_SIZE:\n",
    "                    valid_lbls = arr[WINDOW_SIZE//2 : -(WINDOW_SIZE//2)]\n",
    "                    pos_counts += valid_lbls.sum(axis=0)\n",
    "                    total_samples += len(valid_lbls)\n",
    "        \n",
    "        raw_weights = (total_samples - pos_counts) / (pos_counts + 1e-6)\n",
    "        raw_weights = np.clip(raw_weights, 1.0, 100.0) \n",
    "        pos_weight_val = torch.tensor(raw_weights, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "        # --- MODEL SETUP ---\n",
    "        n_feat_in = len(ref_cols)\n",
    "        model = MouseTCN(n_feat=n_feat_in, n_class=len(ref_label_cols)).to(DEVICE)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        scaler_amp = GradScaler(enabled=torch.cuda.is_available())\n",
    "        criterion = FocalBCEWithLogitsLoss(pos_weight=pos_weight_val, gamma=1.0)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "        save_path = f\"{MODEL_DIR}/model_sec{section}_{mode}_fold{fold}.pth\"\n",
    "        early_stopping = EarlyStopping(patience=CFG.patience, min_delta=0.001)\n",
    "        \n",
    "        # --- TRAINING LOOP ---\n",
    "        for epoch in range(EPOCHS): \n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            # Progress bar sẽ chạy mượt hơn nhiều\n",
    "            for x_batch, y_batch in tqdm(loader_train, desc=f\"Ep {epoch+1}\", leave=False):\n",
    "                x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(x_batch)\n",
    "                loss = criterion(pred, y_batch)\n",
    "                if torch.isnan(loss): continue\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_probs, val_true = [], []\n",
    "            with torch.no_grad():\n",
    "                for x_b, y_b in loader_val:\n",
    "                    val_probs.append(torch.sigmoid(model(x_b.to(DEVICE))).cpu())\n",
    "                    val_true.append(y_b)\n",
    "            \n",
    "            mean_f1 = 0.0\n",
    "            if val_probs:\n",
    "                vp = torch.cat(val_probs).numpy()\n",
    "                vt = torch.cat(val_true).numpy()\n",
    "                mean_f1 = f1_score(vt, (vp > 0.5).astype(int), average='macro', zero_division=0)\n",
    "                \n",
    "                avg_train_loss = train_loss / len(loader_train) if len(loader_train) > 0 else 0\n",
    "                print(f\"Ep {epoch+1}: Loss {avg_train_loss:.4f} | Val F1: {mean_f1:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "                \n",
    "                scheduler.step(mean_f1)\n",
    "                early_stopping(mean_f1, model, save_path)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping triggered!\")\n",
    "                    break\n",
    "        \n",
    "        # --- RESULT ---\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "        model.eval()\n",
    "        val_probs, val_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for x_b, y_b in loader_val:\n",
    "                val_probs.append(torch.sigmoid(model(x_b.to(DEVICE))).cpu())\n",
    "                val_true.append(y_b)\n",
    "        vp, vt = torch.cat(val_probs).numpy(), torch.cat(val_true).numpy()\n",
    "        \n",
    "        print(f\"\\n--- Final Threshold Tuning Fold {fold+1} ---\")\n",
    "        best_thrs, best_f1s = tune_thresholds_per_class(vt, vp, ref_label_cols)\n",
    "        fold_scores.append(np.mean(list(best_f1s.values())))\n",
    "        for k, v in best_f1s.items():\n",
    "            print(f\"\\t{k}: {v:.4f} (thr={best_thrs[k]:.2f})\")\n",
    "            \n",
    "        with open(f\"{MODEL_DIR}/thresholds_sec{section}_{mode}_fold{fold}.json\", \"w\") as f: json.dump(best_thrs, f)\n",
    "        joblib.dump(scaler, f\"{MODEL_DIR}/scaler_sec{section}_{mode}_fold{fold}.pkl\")\n",
    "        \n",
    "        # --- CLEANUP ---\n",
    "        del optimizer, loader_train, loader_val, ds_train, ds_val\n",
    "        del train_feats, val_feats, train_lbls, val_lbls\n",
    "        \n",
    "        if fold < n_splits - 1:\n",
    "            del model\n",
    "            del scaler \n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"\\n>>> MEAN F1 OVER {n_splits} FOLDS: {np.mean(fold_scores):.4f} <<<\")\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "204b698c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:51:22.336688Z",
     "iopub.status.busy": "2025-12-09T12:51:22.335519Z",
     "iopub.status.idle": "2025-12-09T12:51:22.361151Z",
     "shell.execute_reply": "2025-12-09T12:51:22.360430Z",
     "shell.execute_reply.started": "2025-12-09T12:51:22.336644Z"
    },
    "papermill": {
     "duration": 0.03047,
     "end_time": "2025-12-05T10:46:34.948024",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.917554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. MODEL + SCALER\n",
    "# ==========================================\n",
    "def load_resnet_resources(section, mode, n_folds=3, device='cuda'):\n",
    "    print(f\"Loading TCN Ensemble ({n_folds} Folds) for Section {section}...\")\n",
    "    MODEL_DIR = getattr(CFG, 'model_dir', CFG.model_name)\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    base_dir = MODEL_DIR\n",
    "\n",
    "    pack = {\n",
    "        'scalers': [],\n",
    "        'models': [],\n",
    "        'thresholds': {},\n",
    "        'n_feat': 0,\n",
    "        'action_names': []\n",
    "    }\n",
    "\n",
    "    # Load scalers + models\n",
    "    for fold in range(n_folds):\n",
    "        scaler_path = f\"{base_dir}/scaler_sec{section}_{mode}_fold{fold}.pkl\"\n",
    "        if not os.path.exists(scaler_path):\n",
    "            continue\n",
    "        pack['scalers'].append(joblib.load(scaler_path))\n",
    "        model_path = f\"{base_dir}/model_sec{section}_{mode}_fold{fold}.pth\"\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        state = torch.load(model_path, map_location=device)\n",
    "        conv_weight_keys = [k for k in state.keys() if getattr(state[k], 'ndim', 0) == 3 and 'weight' in k]\n",
    "        if not conv_weight_keys:\n",
    "            raise KeyError('No conv1d weight found in state dict')\n",
    "        first_conv = sorted(conv_weight_keys)[0]\n",
    "        pack['n_feat'] = state[first_conv].shape[1]\n",
    "        last_key = [k for k in state.keys() if 'weight' in k][-1]\n",
    "        n_class = state[last_key].shape[0]\n",
    "        model = MouseTCN(n_feat=pack['n_feat'], n_class=n_class).to(device)\n",
    "        model.load_state_dict(state); model.eval()\n",
    "        pack['models'].append(model)\n",
    "\n",
    "    # thresholds\n",
    "    avg_thrs = {}; counts = {}; json_found = False\n",
    "    for fold in range(n_folds):\n",
    "        json_path = f\"{base_dir}/thresholds_sec{section}_{mode}_fold{fold}.json\"\n",
    "        if os.path.exists(json_path):\n",
    "            json_found = True\n",
    "            with open(json_path, 'r') as f:\n",
    "                thrs = json.load(f)\n",
    "            for k, v in thrs.items():\n",
    "                avg_thrs[k] = avg_thrs.get(k, 0.0) + v\n",
    "                counts[k] = counts.get(k, 0) + 1\n",
    "    if not json_found:\n",
    "        print(f\"Warning: No threshold files found for Sec {section}. Using default names.\")\n",
    "        dummy_actions = [f\"action_{i}\" for i in range(n_class)]\n",
    "        for act in dummy_actions: avg_thrs[act] = 0.5\n",
    "        pack['action_names'] = dummy_actions\n",
    "    else:\n",
    "        for k in avg_thrs:\n",
    "            if counts.get(k, 0) > 0:\n",
    "                avg_thrs[k] /= counts[k]\n",
    "        pack['action_names'] = list(avg_thrs.keys())\n",
    "    pack['thresholds'] = avg_thrs\n",
    "\n",
    "    print(f\"-> Detected: n_feat={pack['n_feat']}, n_class={len(pack['action_names'])}\")\n",
    "    print(f\"-> Loaded {len(pack['models'])} models.\")\n",
    "    return pack\n",
    "\n",
    "# ==========================================\n",
    "# 2. PREDICT MULTICLASS (t? xgboost)\n",
    "# ==========================================\n",
    "def predict_multiclass(pred, meta, thresholds):\n",
    "    pred_smoothed = pred.rolling(window=5, min_periods=1, center=True).mean()\n",
    "    threshold_array = np.array([thresholds.get(col, 0.27) for col in pred.columns])\n",
    "    margins = pred_smoothed.values - threshold_array[None, :]\n",
    "\n",
    "    ama = np.argmax(margins, axis=1)\n",
    "    max_margin = margins[np.arange(len(ama)), ama]\n",
    "    ama = np.where(max_margin >= 0.0, ama, -1)\n",
    "    ama = pd.Series(ama, index=meta.video_frame)\n",
    "\n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "    mask = ama_changes.values >= 0\n",
    "    mask[-1] = False\n",
    "\n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id': meta_changes['video_id'][mask].values,\n",
    "        'agent_id': meta_changes['agent_id'][mask].values,\n",
    "        'target_id': meta_changes['target_id'][mask].values,\n",
    "        'action': pred.columns[ama_changes[mask].values],\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame': ama_changes.index[1:][mask[:-1]]\n",
    "    })\n",
    "\n",
    "    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n",
    "    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n",
    "    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n",
    "    for i in range(len(submission_part)):\n",
    "        vid = submission_part.video_id.iloc[i]\n",
    "        ag = submission_part.agent_id.iloc[i]\n",
    "        tg = submission_part.target_id.iloc[i]\n",
    "        if i < len(stop_video_id):\n",
    "            if stop_video_id[i] != vid or stop_agent_id[i] != ag or stop_target_id[i] != tg:\n",
    "                new_stop_frame = meta.query('(video_id == @vid)').video_frame.max() + 1\n",
    "                submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "        else:\n",
    "            new_stop_frame = meta.query('(video_id == @vid)').video_frame.max() + 1\n",
    "            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "\n",
    "    duration = submission_part.stop_frame - submission_part.start_frame\n",
    "    submission_part = submission_part[duration >= 3].reset_index(drop=True)\n",
    "    return submission_part\n",
    "\n",
    "# ==========================================\n",
    "# 3. SUBMIT\n",
    "# ==========================================\n",
    "def submit(test_subset, fps_lookup, body_parts, mode, section, thresholds=None, is_train=False):\n",
    "    submission_parts = []\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    window_size = WINDOW_SIZE\n",
    "\n",
    "    try:\n",
    "        pack = load_resnet_resources(section, mode, n_folds=CFG.n_splits, device=device)\n",
    "        action_names = pack['action_names']\n",
    "        final_thrs = pack['thresholds']\n",
    "        expected_feat = pack['n_feat']\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models for Sec {section}: {e}\")\n",
    "        return []\n",
    "\n",
    "    sample_gen = generate_mouse_data(test_subset, mode, is_train=is_train)\n",
    "    for _, track_df, meta_df, actions in tqdm(sample_gen, desc=f\"Infer Sec {section}\"):\n",
    "        if is_train and not isinstance(actions, (list, tuple)):\n",
    "            actions = list(actions.columns)\n",
    "        video_id = meta_df[\"video_id\"].iloc[0] if \"video_id\" in meta_df.columns else \"Unknown\"\n",
    "        agent_id = meta_df[\"agent_id\"].iloc[0] if \"agent_id\" in meta_df.columns else \"unknown_agent\"\n",
    "        target_id = meta_df[\"target_id\"].iloc[0] if \"target_id\" in meta_df.columns else \"unknown_target\"\n",
    "        try:\n",
    "            fps = _fps_from_meta(meta_df, fps_lookup, default_fps=30)\n",
    "            X = transform_single(track_df, body_parts, fps) if mode == \"single\" else transform_pair(track_df, body_parts, fps)\n",
    "            X = X.values if hasattr(X, 'values') else X\n",
    "            X = np.nan_to_num(X.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            if expected_feat is None:\n",
    "                expected_feat = X.shape[1]\n",
    "            if X.shape[1] != expected_feat:\n",
    "                if X.shape[1] < expected_feat:\n",
    "                    pad = np.zeros((X.shape[0], expected_feat - X.shape[1]), dtype=np.float32)\n",
    "                    X = np.hstack([X, pad])\n",
    "                else:\n",
    "                    X = X[:, :expected_feat]\n",
    "\n",
    "            \n",
    "            n_frames = len(X)\n",
    "            if n_frames < window_size or not action_names:\n",
    "                continue\n",
    "            n_windows = max(1, n_frames - window_size + 1)\n",
    "            n_actions = len(action_names)\n",
    "            accum_probs = np.zeros((n_windows, n_actions), dtype=np.float32)\n",
    "            n_folds = len(pack[\"models\"])\n",
    "            infer_bs = getattr(CFG, 'infer_batch_size', 512)\n",
    "\n",
    "            for i in range(n_folds):\n",
    "                scaler = pack['scalers'][i]\n",
    "                model = pack['models'][i]\n",
    "                X_scaled = scaler.transform(np.nan_to_num(X))\n",
    "                for start in range(0, n_windows, infer_bs):\n",
    "                    end = min(start + infer_bs, n_windows)\n",
    "                    windows = np.array([X_scaled[t: t+window_size] for t in range(start, end)], dtype=np.float32)\n",
    "                    inp = torch.tensor(windows, dtype=torch.float32).transpose(1, 2).to(device)\n",
    "                    with torch.no_grad():\n",
    "                        probs = torch.sigmoid(model(inp)).cpu().numpy()\n",
    "                        accum_probs[start:end] += probs\n",
    "                    del inp, windows\n",
    "                del X_scaled\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            center_probs = accum_probs / float(n_folds)\n",
    "            full_probs = np.zeros((n_frames, len(action_names)), dtype=float)\n",
    "            offset = window_size // 2\n",
    "            full_probs[offset: offset + len(center_probs)] = center_probs\n",
    "            full_probs[:offset] = center_probs[0]\n",
    "            full_probs[offset + len(center_probs):] = center_probs[-1]\n",
    "\n",
    "            pred_df = pd.DataFrame(full_probs, columns=action_names, index=meta_df['video_frame'])\n",
    "            meta_use = meta_df[['video_id','agent_id','target_id','video_frame']]\n",
    "            submission_part = predict_multiclass(pred_df, meta_use, final_thrs)\n",
    "            submission_parts.append(submission_part)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"!!! Error processing video {video_id}: {e}\")\n",
    "            gc.collect()\n",
    "            continue\n",
    "\n",
    "    if submission_parts:\n",
    "        return [pd.concat(submission_parts, ignore_index=True)]\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "647a9848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.292806Z",
     "iopub.status.busy": "2025-12-09T12:39:00.292502Z",
     "iopub.status.idle": "2025-12-09T12:39:00.308718Z",
     "shell.execute_reply": "2025-12-09T12:39:00.308155Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.292754Z"
    },
    "papermill": {
     "duration": 0.020006,
     "end_time": "2025-12-05T10:46:34.975048",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.955042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "\n",
    "def process_mode(mode, subset, body_parts, fps_lookup, section, thresholds, f1_list, submission_list):\n",
    "    # validate or test\n",
    "    if CFG.mode == \"validate\":\n",
    "        data_list, label_list, meta_list = [], [], []\n",
    "\n",
    "        for switch, data, meta, label in generate_mouse_data(subset):\n",
    "            if switch != mode:\n",
    "                continue\n",
    "            data_list.append(data)\n",
    "            meta_list.append(meta)\n",
    "            label_list.append(label)\n",
    "            del data, meta, label\n",
    "        gc.collect()\n",
    "\n",
    "        if len(data_list) == 0:\n",
    "            return  # no sample for this mode\n",
    "\n",
    "        # features for each sample\n",
    "        feats_parts = []\n",
    "        for data_i, meta_i in zip(data_list, meta_list):\n",
    "            fps_i = _fps_from_meta(meta_i, fps_lookup, default_fps=30.0)\n",
    "            if mode == \"single\":\n",
    "                X_i = transform_single(data_i, body_parts, fps_i)\n",
    "            else:\n",
    "                X_i = transform_pair(data_i, body_parts, fps_i)\n",
    "\n",
    "            feats_parts.append(X_i.astype(np.float32))\n",
    "            del X_i, fps_i\n",
    "        gc.collect()\n",
    "\n",
    "        # --- CNN ---\n",
    "        print(f\"Start training CNN for section {section}\")\n",
    "\n",
    "        # training CNN\n",
    "        model, scaler = train_evaluate_cnn(feats_parts, label_list, meta_list, section, mode)\n",
    "\n",
    "        # Load thresholds\n",
    "        try:\n",
    "            pack = load_resnet_resources(section, mode, n_folds=CFG.n_splits, device=(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "            thresholds[mode].setdefault(str(section), {})\n",
    "            thresholds[mode][str(section)] = pack.get(\"thresholds\", {})\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not load thresholds for section {section}: {e}\")\n",
    "\n",
    "        # Sau khi train, chạy inference trên tập train (validate) sinh submission_list\n",
    "        temp_sub_list = submit(\n",
    "            test_subset=subset,\n",
    "            body_parts=body_parts,\n",
    "            fps_lookup=fps_lookup,\n",
    "            mode=mode,\n",
    "            section=section,\n",
    "            thresholds=thresholds,\n",
    "            is_train=True\n",
    "        )\n",
    "        for df in temp_sub_list:\n",
    "            submission_list.append(df)\n",
    "\n",
    "        # Cleanup\n",
    "        del feats_parts, label_list, meta_list\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        print(f\"Predicting Section {section} using ResNet Ensemble...\")\n",
    "\n",
    "        temp_sub_list = submit(\n",
    "            test_subset=subset,\n",
    "            body_parts=body_parts,\n",
    "            fps_lookup=fps_lookup,\n",
    "            mode=mode,\n",
    "            section=section,\n",
    "            thresholds=None,\n",
    "            is_train=False\n",
    "        )\n",
    "\n",
    "        for df in temp_sub_list:\n",
    "            submission_list.append(df)\n",
    "\n",
    "        del temp_sub_list; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4007c30d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:39:00.309652Z",
     "iopub.status.busy": "2025-12-09T12:39:00.309422Z",
     "iopub.status.idle": "2025-12-09T12:39:00.326964Z",
     "shell.execute_reply": "2025-12-09T12:39:00.326381Z",
     "shell.execute_reply.started": "2025-12-09T12:39:00.309632Z"
    },
    "papermill": {
     "duration": 0.013595,
     "end_time": "2025-12-05T10:46:35.008331",
     "exception": false,
     "start_time": "2025-12-05T10:46:34.994736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "thresholds = {\n",
    "    \"single\": {},\n",
    "    \"pair\": {}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a79ef687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T12:51:35.744585Z",
     "iopub.status.busy": "2025-12-09T12:51:35.744306Z",
     "iopub.status.idle": "2025-12-09T15:36:51.604766Z",
     "shell.execute_reply": "2025-12-09T15:36:51.603553Z",
     "shell.execute_reply.started": "2025-12-09T12:51:35.744563Z"
    },
    "papermill": {
     "duration": 951.109901,
     "end_time": "2025-12-05T11:02:26.124881",
     "exception": false,
     "start_time": "2025-12-05T10:46:35.014980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', 'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "\n",
      "Start training CNN for section 1\n",
      ">>> Optimizing: Converting DataFrames to Numpy (CPU heavy once, then fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To Numpy: 100%|██████████| 22/22 [00:01<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> TRAINING FOLD 1/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.2265 | Val F1: 0.6886 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.1215 | Val F1: 0.7210 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 1 ---\n",
      "\trear: 0.5617 (thr=0.82)\n",
      "\n",
      ">>> TRAINING FOLD 2/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.2255 | Val F1: 0.7255 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.1245 | Val F1: 0.7123 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 2 ---\n",
      "\trear: 0.5381 (thr=0.65)\n",
      "\n",
      ">>> TRAINING FOLD 3/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.2252 | Val F1: 0.7785 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.1278 | Val F1: 0.7524 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 3 ---\n",
      "\trear: 0.6346 (thr=0.66)\n",
      "\n",
      ">>> MEAN F1 OVER 3 FOLDS: 0.5782 <<<\n",
      "Loading TCN Ensemble (3 Folds) for Section 1...\n",
      "-> Detected: n_feat=142, n_class=1\n",
      "-> Loaded 3 models.\n",
      "Loading TCN Ensemble (3 Folds) for Section 1...\n",
      "-> Detected: n_feat=142, n_class=1\n",
      "-> Loaded 3 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer Sec 1: 22it [01:09,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training CNN for section 1\n",
      ">>> Optimizing: Converting DataFrames to Numpy (CPU heavy once, then fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To Numpy: 100%|██████████| 72/72 [00:04<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> TRAINING FOLD 1/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.0382 | Val F1: 0.2476 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0190 | Val F1: 0.2880 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 1 ---\n",
      "\tapproach: 0.3531 (thr=0.94)\n",
      "\tattack: 0.4680 (thr=0.92)\n",
      "\tavoid: 0.4980 (thr=0.92)\n",
      "\tchase: 0.5390 (thr=0.92)\n",
      "\tchaseattack: 0.5379 (thr=0.97)\n",
      "\tsubmit: 0.1103 (thr=0.30)\n",
      "\n",
      ">>> TRAINING FOLD 2/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.0439 | Val F1: 0.2043 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0231 | Val F1: 0.2325 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 2 ---\n",
      "\tapproach: 0.3962 (thr=0.87)\n",
      "\tattack: 0.4918 (thr=0.91)\n",
      "\tavoid: 0.4875 (thr=0.83)\n",
      "\tchase: 0.2641 (thr=0.95)\n",
      "\tchaseattack: 0.5471 (thr=0.90)\n",
      "\tsubmit: 0.1795 (thr=0.57)\n",
      "\n",
      ">>> TRAINING FOLD 3/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.0380 | Val F1: 0.1494 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0202 | Val F1: 0.1981 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 3 ---\n",
      "\tapproach: 0.3539 (thr=0.92)\n",
      "\tattack: 0.3458 (thr=0.95)\n",
      "\tavoid: 0.4182 (thr=0.81)\n",
      "\tchase: 0.5001 (thr=0.84)\n",
      "\tchaseattack: 0.4040 (thr=0.99)\n",
      "\tsubmit: 0.0147 (thr=0.08)\n",
      "\n",
      ">>> MEAN F1 OVER 3 FOLDS: 0.3839 <<<\n",
      "Loading TCN Ensemble (3 Folds) for Section 1...\n",
      "-> Detected: n_feat=164, n_class=6\n",
      "-> Loaded 3 models.\n",
      "Loading TCN Ensemble (3 Folds) for Section 1...\n",
      "-> Detected: n_feat=164, n_class=6\n",
      "-> Loaded 3 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer Sec 1: 72it [04:11,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of submission_list: 94\n",
      "\n",
      "2/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'hip_left', 'hip_right', 'lateral_left', 'lateral_right', 'nose', 'spine_1', 'spine_2', 'tail_base', 'tail_middle_1', 'tail_middle_2', 'tail_tip']\n",
      "\n",
      "Start training CNN for section 2\n",
      ">>> Optimizing: Converting DataFrames to Numpy (CPU heavy once, then fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To Numpy: 100%|██████████| 32/32 [00:00<00:00, 32.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> TRAINING FOLD 1/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.0545 | Val F1: 0.0630 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0330 | Val F1: 0.0535 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 1 ---\n",
      "\thuddle: 0.2463 (thr=0.82)\n",
      "\trear: 0.0000 (thr=0.50)\n",
      "\tselfgroom: 0.0000 (thr=0.50)\n",
      "\n",
      ">>> TRAINING FOLD 2/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.0500 | Val F1: 0.1153 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0285 | Val F1: 0.1365 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 2 ---\n",
      "\thuddle: 0.4298 (thr=0.71)\n",
      "\trear: 0.0000 (thr=0.50)\n",
      "\tselfgroom: 0.0000 (thr=0.50)\n",
      "\n",
      ">>> TRAINING FOLD 3/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.0666 | Val F1: 0.1991 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0389 | Val F1: 0.1934 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 3 ---\n",
      "\thuddle: 0.6253 (thr=0.71)\n",
      "\trear: 0.0000 (thr=0.50)\n",
      "\tselfgroom: 0.0000 (thr=0.50)\n",
      "\n",
      ">>> MEAN F1 OVER 3 FOLDS: 0.1446 <<<\n",
      "Loading TCN Ensemble (3 Folds) for Section 2...\n",
      "-> Detected: n_feat=151, n_class=3\n",
      "-> Loaded 3 models.\n",
      "Loading TCN Ensemble (3 Folds) for Section 2...\n",
      "-> Detected: n_feat=151, n_class=3\n",
      "-> Loaded 3 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer Sec 2: 32it [01:09,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training CNN for section 2\n",
      ">>> Optimizing: Converting DataFrames to Numpy (CPU heavy once, then fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To Numpy: 100%|██████████| 42/42 [00:01<00:00, 28.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> TRAINING FOLD 1/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.1394 | Val F1: 0.1026 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0964 | Val F1: 0.1227 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 1 ---\n",
      "\tintromit: 0.0000 (thr=0.50)\n",
      "\tmount: 0.0000 (thr=0.50)\n",
      "\treciprocalsniff: 0.3711 (thr=0.74)\n",
      "\tsniff: 0.0000 (thr=0.50)\n",
      "\tsniffgenital: 0.3778 (thr=0.75)\n",
      "\n",
      ">>> TRAINING FOLD 2/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.1413 | Val F1: 0.1032 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0933 | Val F1: 0.1245 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 2 ---\n",
      "\tintromit: 0.0000 (thr=0.50)\n",
      "\tmount: 0.0000 (thr=0.50)\n",
      "\treciprocalsniff: 0.3181 (thr=0.78)\n",
      "\tsniff: 0.0000 (thr=0.50)\n",
      "\tsniffgenital: 0.5082 (thr=0.80)\n",
      "\n",
      ">>> TRAINING FOLD 3/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.1439 | Val F1: 0.1087 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0942 | Val F1: 0.1323 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 3 ---\n",
      "\tintromit: 0.0000 (thr=0.50)\n",
      "\tmount: 0.0000 (thr=0.50)\n",
      "\treciprocalsniff: 0.3365 (thr=0.70)\n",
      "\tsniff: 0.0000 (thr=0.50)\n",
      "\tsniffgenital: 0.3769 (thr=0.58)\n",
      "\n",
      ">>> MEAN F1 OVER 3 FOLDS: 0.1526 <<<\n",
      "Loading TCN Ensemble (3 Folds) for Section 2...\n",
      "-> Detected: n_feat=183, n_class=5\n",
      "-> Loaded 3 models.\n",
      "Loading TCN Ensemble (3 Folds) for Section 2...\n",
      "-> Detected: n_feat=183, n_class=5\n",
      "-> Loaded 3 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer Sec 2: 42it [01:57,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of submission_list: 168\n",
      "\n",
      "3/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "\n",
      "Start training CNN for section 3\n",
      ">>> Optimizing: Converting DataFrames to Numpy (CPU heavy once, then fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To Numpy: 100%|██████████| 37/37 [00:04<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> TRAINING FOLD 1/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.1732 | Val F1: 0.6819 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0944 | Val F1: 0.7306 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 1 ---\n",
      "\trear: 0.5163 (thr=0.73)\n",
      "\n",
      ">>> TRAINING FOLD 2/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.1578 | Val F1: 0.6435 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0888 | Val F1: 0.6514 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 2 ---\n",
      "\trear: 0.4648 (thr=0.87)\n",
      "\n",
      ">>> TRAINING FOLD 3/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.1434 | Val F1: 0.6074 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0782 | Val F1: 0.6181 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 3 ---\n",
      "\trear: 0.4028 (thr=0.91)\n",
      "\n",
      ">>> MEAN F1 OVER 3 FOLDS: 0.4613 <<<\n",
      "Loading TCN Ensemble (3 Folds) for Section 3...\n",
      "-> Detected: n_feat=142, n_class=1\n",
      "-> Loaded 3 models.\n",
      "Loading TCN Ensemble (3 Folds) for Section 3...\n",
      "-> Detected: n_feat=142, n_class=1\n",
      "-> Loaded 3 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer Sec 3: 37it [04:11,  6.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training CNN for section 3\n",
      ">>> Optimizing: Converting DataFrames to Numpy (CPU heavy once, then fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To Numpy: 100%|██████████| 114/114 [00:15<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> TRAINING FOLD 1/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.1296 | Val F1: 0.0894 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0857 | Val F1: 0.0853 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 1 ---\n",
      "\tapproach: 0.3685 (thr=0.70)\n",
      "\tattack: 0.0902 (thr=0.89)\n",
      "\tavoid: 0.1824 (thr=0.88)\n",
      "\tchase: 0.0204 (thr=0.78)\n",
      "\tchaseattack: 0.1263 (thr=0.87)\n",
      "\tsubmit: 0.1276 (thr=0.56)\n",
      "\n",
      ">>> TRAINING FOLD 2/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.1408 | Val F1: 0.0603 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0893 | Val F1: 0.0523 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 2 ---\n",
      "\tapproach: 0.1710 (thr=0.84)\n",
      "\tattack: 0.1327 (thr=0.76)\n",
      "\tavoid: 0.2225 (thr=0.90)\n",
      "\tchase: 0.0263 (thr=0.67)\n",
      "\tchaseattack: 0.0860 (thr=0.62)\n",
      "\tsubmit: 0.0525 (thr=0.96)\n",
      "\n",
      ">>> TRAINING FOLD 3/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Loss 0.1471 | Val F1: 0.0479 | LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2: Loss 0.0981 | Val F1: 0.0719 | LR: 0.001000\n",
      "\n",
      "--- Final Threshold Tuning Fold 3 ---\n",
      "\tapproach: 0.3418 (thr=0.82)\n",
      "\tattack: 0.0430 (thr=0.95)\n",
      "\tavoid: 0.1339 (thr=0.84)\n",
      "\tchase: 0.0207 (thr=0.78)\n",
      "\tchaseattack: 0.0766 (thr=0.95)\n",
      "\tsubmit: 0.0638 (thr=0.56)\n",
      "\n",
      ">>> MEAN F1 OVER 3 FOLDS: 0.1270 <<<\n",
      "Loading TCN Ensemble (3 Folds) for Section 3...\n",
      "-> Detected: n_feat=164, n_class=6\n",
      "-> Loaded 3 models.\n",
      "Loading TCN Ensemble (3 Folds) for Section 3...\n",
      "-> Detected: n_feat=164, n_class=6\n",
      "-> Loaded 3 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer Sec 3: 114it [14:55,  7.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of submission_list: 319\n",
      "\n",
      "4/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'nose', 'tail_base', 'tail_tip']\n",
      "\n",
      "Start training CNN for section 4\n",
      ">>> Optimizing: Converting DataFrames to Numpy (CPU heavy once, then fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To Numpy: 100%|██████████| 82/82 [00:05<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> TRAINING FOLD 1/3 <<<\n",
      "Fitting Scaler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47/1644084260.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         process_mode(\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pair\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_47/104442482.py\u001b[0m in \u001b[0;36mprocess_mode\u001b[0;34m(mode, subset, body_parts, fps_lookup, section, thresholds, f1_list, submission_list)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# training CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_evaluate_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Load thresholds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_47/2593475069.py\u001b[0m in \u001b[0;36mtrain_evaluate_cnn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f1_list = []\n",
    "submission_list = []\n",
    "import traceback\n",
    "\n",
    "# for section in range(1, len(body_parts_tracked_list)):\n",
    "for section in range(1, len(body_parts_tracked_list)):\n",
    "    body_parts_tracked_str = body_parts_tracked_list[section]\n",
    "\n",
    "    try:\n",
    "        body_parts = json.loads(body_parts_tracked_str)\n",
    "        print(f\"{section}/{len(body_parts_tracked_list)-1} Processing videos with: {body_parts}\\n\")\n",
    "\n",
    "        if len(body_parts) > 5:\n",
    "            body_parts = [b for b in body_parts if b not in DROP_BODY_PARTS]\n",
    "\n",
    "        if CFG.mode == \"validate\":\n",
    "            subset =  train[train.body_parts_tracked == body_parts_tracked_str]\n",
    "        else:\n",
    "            subset = test[test.body_parts_tracked == body_parts_tracked_str]\n",
    "\n",
    "        # lookup FPS\n",
    "        fps_lookup = (\n",
    "            subset[[\"video_id\", \"frames_per_second\"]]\n",
    "            .drop_duplicates(\"video_id\")\n",
    "            .set_index(\"video_id\")[\"frames_per_second\"]\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        # single\n",
    "        process_mode(\n",
    "            mode=\"single\",\n",
    "            subset=subset,\n",
    "            body_parts=body_parts,\n",
    "            fps_lookup=fps_lookup,\n",
    "            section=section,\n",
    "            thresholds=thresholds,\n",
    "            f1_list=f1_list,\n",
    "            submission_list=submission_list,\n",
    "        )\n",
    "\n",
    "        # pair\n",
    "        process_mode(\n",
    "            mode=\"pair\",\n",
    "            subset=subset,\n",
    "            body_parts=body_parts,\n",
    "            fps_lookup=fps_lookup,\n",
    "            section=section,\n",
    "            thresholds=thresholds,\n",
    "            f1_list=f1_list,\n",
    "            submission_list=submission_list,\n",
    "        )\n",
    "\n",
    "        print(f\"Length of submission_list: {len(submission_list)}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\tError: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f7aa40",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-09T12:46:16.089204Z",
     "iopub.status.idle": "2025-12-09T12:46:16.089451Z",
     "shell.execute_reply": "2025-12-09T12:46:16.089346Z",
     "shell.execute_reply.started": "2025-12-09T12:46:16.089335Z"
    },
    "papermill": {
     "duration": 0.221628,
     "end_time": "2025-12-05T11:02:26.358341",
     "exception": false,
     "start_time": "2025-12-05T11:02:26.136713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==========================================\n",
    "# FINAL SUBMISSION GENERATION\n",
    "# ==========================================\n",
    "\n",
    "def convert_frames_to_intervals(df_frames, meta_df):\n",
    "    \"\"\"\n",
    "    Chuyển DataFrame d?ng Frame-wise (0/1) sang Intervals (start/stop).\n",
    "    Gi? nguy?n video_id / agent_id / target_id t? inference v? g?p c?c ?o?n li?n t?c.\n",
    "    \"\"\"\n",
    "    required_cols = {\"video_id\", \"agent_id\", \"target_id\", \"frame\"}\n",
    "    missing = required_cols - set(df_frames.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    intervals = []\n",
    "\n",
    "    grouped = df_frames.groupby(['video_id', 'agent_id', 'target_id'])\n",
    "\n",
    "    print(\"Converting frames to intervals...\")\n",
    "    for (vid, agent, target), grp in tqdm(grouped):\n",
    "        act_cols = [c for c in grp.columns if c not in required_cols]\n",
    "        grp = grp.sort_values('frame')\n",
    "        frames = grp['frame'].values\n",
    "\n",
    "        for action in act_cols:\n",
    "            vals = grp[action].values\n",
    "            if vals.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            padded = np.r_[0, vals, 0]\n",
    "            diff = np.diff(padded)\n",
    "            starts = np.where(diff == 1)[0]\n",
    "            stops = np.where(diff == -1)[0]\n",
    "\n",
    "            for s, e in zip(starts, stops):\n",
    "                start_f = frames[s]\n",
    "                stop_f = frames[e-1] + 1\n",
    "                intervals.append({\n",
    "                    'video_id': vid,\n",
    "                    'agent_id': agent,\n",
    "                    'target_id': target,\n",
    "                    'action': action,\n",
    "                    'start_frame': start_f,\n",
    "                    'stop_frame': stop_f\n",
    "                })\n",
    "\n",
    "    # G?p c?c interval li?n k?/ch?ng nhau c?a c?ng action\n",
    "    df_int = pd.DataFrame(intervals)\n",
    "    if not df_int.empty:\n",
    "        merged = []\n",
    "        df_int = df_int.sort_values(['video_id', 'agent_id', 'target_id', 'action', 'start_frame'])\n",
    "        for key, grp in df_int.groupby(['video_id', 'agent_id', 'target_id', 'action']):\n",
    "            grp = grp.sort_values('start_frame')\n",
    "            cur = None\n",
    "            for _, row in grp.iterrows():\n",
    "                if cur is None:\n",
    "                    cur = row[['video_id','agent_id','target_id','action','start_frame','stop_frame']].to_dict()\n",
    "                    continue\n",
    "                # n?i c?c ?o?n ch?m nhau ho?c ch?ng nhau\n",
    "                if row['start_frame'] <= cur['stop_frame'] or row['start_frame'] == cur['stop_frame'] + 1:\n",
    "                    cur['stop_frame'] = max(cur['stop_frame'], row['stop_frame'])\n",
    "                else:\n",
    "                    merged.append(cur)\n",
    "                    cur = row[['video_id','agent_id','target_id','action','start_frame','stop_frame']].to_dict()\n",
    "            if cur is not None:\n",
    "                merged.append(cur)\n",
    "        df_int = pd.DataFrame(merged)\n",
    "        dur = df_int['stop_frame'] - df_int['start_frame']\n",
    "        df_int = df_int[dur >= 3].reset_index(drop=True)\n",
    "    else:\n",
    "        df_int = pd.DataFrame(columns=['video_id','agent_id','target_id','action','start_frame','stop_frame'])\n",
    "\n",
    "    return df_int\n",
    "\n",
    "# --- T?O SUBMISSION ---\n",
    "\n",
    "if CFG.mode == 'validate':\n",
    "    print(\">>> GENERATING VALIDATION SCORES...\")\n",
    "    if len(submission_list) > 0:\n",
    "        submission_raw = pd.concat(submission_list, axis=0, ignore_index=True).fillna(0)\n",
    "\n",
    "        submission = convert_frames_to_intervals(submission_raw, train) if \"frame\" in submission_raw.columns else submission_raw \n",
    "\n",
    "        if len(submission) > 0:\n",
    "            cleaned_submission = clean_and_fill_submission(submission, train)\n",
    "            print(f\"Competition metric: {score(solution, cleaned_submission, ''):.4f}\")\n",
    "        else:\n",
    "            print(\"Warning: No events detected after conversion.\")\n",
    "\n",
    "        if len(f1_list) > 0:\n",
    "            f1_df = pd.DataFrame(f1_list, columns=['body_parts_tracked_str', 'action', 'binary F1 score'])\n",
    "            print(f\"Mean F1:             {f1_df['binary F1 score'].mean():.4f}\")\n",
    "            joblib.dump(f1_df, f\"{getattr(CFG, 'model_dir', CFG.model_name)}/scores.pkl\")\n",
    "\n",
    "        joblib.dump(thresholds, f\"{getattr(CFG, 'model_dir', CFG.model_name)}/final_thresholds_dict.pkl\")\n",
    "    else:\n",
    "        print(\"Error: Submission list is empty!\")\n",
    "\n",
    "elif CFG.mode == 'submit':\n",
    "    print(\">>> GENERATING FINAL SUBMISSION.CSV...\")\n",
    "\n",
    "    if len(submission_list) > 0:\n",
    "        print(\"Concatenating raw predictions...\")\n",
    "        submission_raw = pd.concat(submission_list, axis=0, ignore_index=True)\n",
    "        submission_raw = submission_raw.fillna(0)\n",
    "\n",
    "        submission = convert_frames_to_intervals(submission_raw, test) if \"frame\" in submission_raw.columns else submission_raw\n",
    "\n",
    "    else:\n",
    "        print(\"Warning: Creating dummy submission because list is empty.\")\n",
    "        submission = pd.DataFrame(dict(\n",
    "            video_id=[438887472], agent_id=['mouse1'], target_id=['self'], \n",
    "            action=['rear'], start_frame=[0], stop_frame=[10]\n",
    "        ))\n",
    "\n",
    "    if len(submission) == 0:\n",
    "        print(\"Warning: No events found! Using dummy row.\")\n",
    "        submission = pd.DataFrame(dict(\n",
    "            video_id=[438887472], agent_id=['mouse1'], target_id=['self'], \n",
    "            action=['rear'], start_frame=[0], stop_frame=[10]\n",
    "        ))\n",
    "\n",
    "    cleaned_submission = clean_and_fill_submission(submission, test, is_train=False)\n",
    "    cleaned_submission.index.name = 'row_id'\n",
    "    cleaned_submission.to_csv('submission.csv')\n",
    "\n",
    "    print(\"Success! saved to submission.csv\")\n",
    "    print(cleaned_submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 976.768565,
   "end_time": "2025-12-05T11:02:29.155649",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-05T10:46:12.387084",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
